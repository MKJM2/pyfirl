{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ty7wphjdn1Ge"
   },
   "source": [
    "**Do some preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ybwA7ptbs_-n",
    "outputId": "5d4c2f38-5c52-4874-bfd5-92703e5ee586"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4 0.6 1. ]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "import os, pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "import sys, os\n",
    "\n",
    "import trajectory as T                      # trajectory generation\n",
    "import optimizer as O                       # stochastic gradient descent optimizer\n",
    "import solver as S                          # MDP solver (value-iteration)\n",
    "import plot as P\n",
    "\n",
    "\n",
    "num_data = 355504\n",
    "\n",
    "\n",
    "np.random.seed(66)\n",
    "\n",
    "def to_interval(istr):\n",
    "    c_left = istr[0]=='['\n",
    "    c_right = istr[-1]==']'\n",
    "    closed = {(True, False): 'left',\n",
    "              (False, True): 'right',\n",
    "              (True, True): 'both',\n",
    "              (False, False): 'neither'\n",
    "              }[c_left, c_right]\n",
    "    left, right = map(pd.to_datetime, istr[1:-1].split(','))\n",
    "    return pd.Interval(left, right, closed)\n",
    "\n",
    "re_split = False\n",
    "frac = [0.4,0.2,0.4]\n",
    "assert np.sum(frac) == 1\n",
    "frac = np.cumsum(frac)\n",
    "print (frac)\n",
    "data_save_path= 'data/'\n",
    "\n",
    "def sliding(gs, window_size = 6):\n",
    "    npr_l = []\n",
    "    for g in gs:\n",
    "        npr = np.concatenate([np.zeros([window_size-1, g.shape[1]]),g])\n",
    "        npr_l.append(sliding_window_view(npr, (window_size, g.shape[1])).squeeze(1))\n",
    "    return np.vstack(npr_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WtuZoGn5tEQ8"
   },
   "outputs": [],
   "source": [
    "# if re_split:\n",
    "\n",
    "aggr_df = pd.read_csv('mimic_iv_hypotensive_cut2.csv',sep = ',', header = 0,converters={1:to_interval}).set_index(['stay_id','time']).sort_index()\n",
    "# create action bins (four actions in total)\n",
    "aggr_df['action'] = aggr_df['bolus(binary)']*2 + aggr_df['vaso(binary)']\n",
    "all_idx = np.random.permutation(aggr_df.index.get_level_values(0).unique())\n",
    "train_df = aggr_df.loc[all_idx[:int(len(all_idx)*frac[0])]].sort_index()\n",
    "test_df = aggr_df.loc[all_idx[int(len(all_idx)*frac[0]):int(len(all_idx)*frac[1])]].sort_index()\n",
    "valid_df = aggr_df.loc[all_idx[int(len(all_idx)*frac[1]):]].sort_index()\n",
    "# print (np.unique(train_df['action'],return_counts=True)[1]*1./len(train_df))\n",
    "# pickle.dump([train_df, test_df, valid_df], open(data_save_path+'processed_mimic_hyp_2.pkl','wb'))\n",
    "drop_columns = ['vaso(amount)','bolus(amount)',\\\n",
    "            'any_treatment(binary)','vaso(binary)','bolus(binary)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gnMu3xMntL-E"
   },
   "outputs": [],
   "source": [
    "# for now drop indicators about bolus and vaso\n",
    "train_df = train_df.drop(columns=drop_columns)\n",
    "test_df = test_df.drop(columns=drop_columns)\n",
    "valid_df = valid_df.drop(columns=drop_columns)\n",
    "\n",
    "#### imputation\n",
    "impute_table = pd.read_csv('mimic_iv_hypotensive_cut2_impute_table.csv',sep=',',header=0).set_index(['feature'])\n",
    "train_df = train_df.fillna(method='ffill')\n",
    "test_df = test_df.fillna(method='ffill')\n",
    "valid_df = valid_df.fillna(method='ffill')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for f in impute_table.index:\n",
    "    train_df[f] = train_df[f].fillna(value = impute_table.loc[f].values[0])\n",
    "    test_df[f] = test_df[f].fillna(value = impute_table.loc[f].values[0])\n",
    "    valid_df[f] = valid_df[f].fillna(value = impute_table.loc[f].values[0])\n",
    "\n",
    "\n",
    "data_non_normalized_df = pd.concat([train_df, valid_df, test_df], axis=0, ignore_index=False).head(num_data).copy()\n",
    "\n",
    "\n",
    "#### standard normalization ####\n",
    "normalize_features = ['creatinine', 'fraction_inspired_oxygen', 'lactate', 'urine_output',\n",
    "                  'alanine_aminotransferase', 'asparate_aminotransferase',\n",
    "                  'mean_blood_pressure', 'diastolic_blood_pressure',\n",
    "                  'systolic_blood_pressure', 'gcs', 'partial_pressure_of_oxygen']\n",
    "mu, std = (train_df[normalize_features]).mean().values,(train_df[normalize_features]).std().values\n",
    "train_df[normalize_features] = (train_df[normalize_features] - mu)/std\n",
    "test_df[normalize_features] = (test_df[normalize_features] - mu)/std\n",
    "valid_df[normalize_features] = (valid_df[normalize_features] - mu)/std\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### create data matrix ####\n",
    "X_train = train_df.loc[:,train_df.columns!='action']\n",
    "y_train = train_df['action']\n",
    "\n",
    "X_test = test_df.loc[:,test_df.columns!='action']\n",
    "y_test = test_df['action']\n",
    "\n",
    "X_valid = valid_df.loc[:, valid_df.columns!='action']\n",
    "y_valid = valid_df['action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "erexoh03tM75"
   },
   "outputs": [],
   "source": [
    "X_df = pd.concat([X_train, X_valid, X_test], axis=0, ignore_index=True).copy()\n",
    "y_df = pd.concat([y_train, y_valid, y_test], axis=0, ignore_index=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lI-t0LodtTfU"
   },
   "outputs": [],
   "source": [
    "data_df = pd.concat([train_df, valid_df, test_df], axis=0, ignore_index=False).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "m5vttBwpCAej"
   },
   "outputs": [],
   "source": [
    "X_non_normailzed = data_non_normalized_df.copy()\n",
    "del X_non_normailzed['action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 996
    },
    "id": "_g_uBsDdEZ_z",
    "outputId": "65783f6f-1c2b-4359-8180-de60f4ad3954"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>creatinine</th>\n",
       "      <th>fraction_inspired_oxygen</th>\n",
       "      <th>lactate</th>\n",
       "      <th>urine_output</th>\n",
       "      <th>alanine_aminotransferase</th>\n",
       "      <th>asparate_aminotransferase</th>\n",
       "      <th>mean_blood_pressure</th>\n",
       "      <th>diastolic_blood_pressure</th>\n",
       "      <th>systolic_blood_pressure</th>\n",
       "      <th>gcs</th>\n",
       "      <th>partial_pressure_of_oxygen</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>temperature</th>\n",
       "      <th>respiratory_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stay_id</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">30004811</th>\n",
       "      <th>[2139-10-06 10:40:29, 2139-10-06 11:40:29)</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.8</td>\n",
       "      <td>80.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[2139-10-06 11:40:29, 2139-10-06 12:40:29)</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.8</td>\n",
       "      <td>80.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[2139-10-06 12:40:29, 2139-10-06 13:40:29)</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[2139-10-06 13:40:29, 2139-10-06 14:40:29)</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[2139-10-06 14:40:29, 2139-10-06 15:40:29)</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">39986775</th>\n",
       "      <th>[2123-10-10 12:18:46, 2123-10-10 13:18:46)</th>\n",
       "      <td>2.7</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.6</td>\n",
       "      <td>125.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>36.833333</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[2123-10-10 13:18:46, 2123-10-10 14:18:46)</th>\n",
       "      <td>2.7</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>36.833333</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[2123-10-10 14:18:46, 2123-10-10 15:18:46)</th>\n",
       "      <td>2.7</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>36.833333</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[2123-10-10 15:18:46, 2123-10-10 16:18:46)</th>\n",
       "      <td>2.7</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>36.777778</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[2123-10-10 16:18:46, 2123-10-10 17:18:46)</th>\n",
       "      <td>2.7</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>36.777778</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>355504 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     creatinine  \\\n",
       "stay_id  time                                                     \n",
       "30004811 [2139-10-06 10:40:29, 2139-10-06 11:40:29)         1.0   \n",
       "         [2139-10-06 11:40:29, 2139-10-06 12:40:29)         1.0   \n",
       "         [2139-10-06 12:40:29, 2139-10-06 13:40:29)         1.0   \n",
       "         [2139-10-06 13:40:29, 2139-10-06 14:40:29)         1.0   \n",
       "         [2139-10-06 14:40:29, 2139-10-06 15:40:29)         1.0   \n",
       "...                                                         ...   \n",
       "39986775 [2123-10-10 12:18:46, 2123-10-10 13:18:46)         2.7   \n",
       "         [2123-10-10 13:18:46, 2123-10-10 14:18:46)         2.7   \n",
       "         [2123-10-10 14:18:46, 2123-10-10 15:18:46)         2.7   \n",
       "         [2123-10-10 15:18:46, 2123-10-10 16:18:46)         2.7   \n",
       "         [2123-10-10 16:18:46, 2123-10-10 17:18:46)         2.7   \n",
       "\n",
       "                                                     fraction_inspired_oxygen  \\\n",
       "stay_id  time                                                                   \n",
       "30004811 [2139-10-06 10:40:29, 2139-10-06 11:40:29)                      0.21   \n",
       "         [2139-10-06 11:40:29, 2139-10-06 12:40:29)                      0.21   \n",
       "         [2139-10-06 12:40:29, 2139-10-06 13:40:29)                      0.21   \n",
       "         [2139-10-06 13:40:29, 2139-10-06 14:40:29)                      0.21   \n",
       "         [2139-10-06 14:40:29, 2139-10-06 15:40:29)                      0.21   \n",
       "...                                                                       ...   \n",
       "39986775 [2123-10-10 12:18:46, 2123-10-10 13:18:46)                      0.40   \n",
       "         [2123-10-10 13:18:46, 2123-10-10 14:18:46)                      0.40   \n",
       "         [2123-10-10 14:18:46, 2123-10-10 15:18:46)                      0.40   \n",
       "         [2123-10-10 15:18:46, 2123-10-10 16:18:46)                      0.50   \n",
       "         [2123-10-10 16:18:46, 2123-10-10 17:18:46)                      0.50   \n",
       "\n",
       "                                                     lactate  urine_output  \\\n",
       "stay_id  time                                                                \n",
       "30004811 [2139-10-06 10:40:29, 2139-10-06 11:40:29)      1.8          80.0   \n",
       "         [2139-10-06 11:40:29, 2139-10-06 12:40:29)      1.8          80.0   \n",
       "         [2139-10-06 12:40:29, 2139-10-06 13:40:29)      3.0          80.0   \n",
       "         [2139-10-06 13:40:29, 2139-10-06 14:40:29)      3.0          80.0   \n",
       "         [2139-10-06 14:40:29, 2139-10-06 15:40:29)      3.0          80.0   \n",
       "...                                                      ...           ...   \n",
       "39986775 [2123-10-10 12:18:46, 2123-10-10 13:18:46)      1.6         125.0   \n",
       "         [2123-10-10 13:18:46, 2123-10-10 14:18:46)      1.6          60.0   \n",
       "         [2123-10-10 14:18:46, 2123-10-10 15:18:46)      1.1          40.0   \n",
       "         [2123-10-10 15:18:46, 2123-10-10 16:18:46)      1.0          40.0   \n",
       "         [2123-10-10 16:18:46, 2123-10-10 17:18:46)      1.0          40.0   \n",
       "\n",
       "                                                     alanine_aminotransferase  \\\n",
       "stay_id  time                                                                   \n",
       "30004811 [2139-10-06 10:40:29, 2139-10-06 11:40:29)                      34.0   \n",
       "         [2139-10-06 11:40:29, 2139-10-06 12:40:29)                      34.0   \n",
       "         [2139-10-06 12:40:29, 2139-10-06 13:40:29)                      34.0   \n",
       "         [2139-10-06 13:40:29, 2139-10-06 14:40:29)                      34.0   \n",
       "         [2139-10-06 14:40:29, 2139-10-06 15:40:29)                      34.0   \n",
       "...                                                                       ...   \n",
       "39986775 [2123-10-10 12:18:46, 2123-10-10 13:18:46)                     164.0   \n",
       "         [2123-10-10 13:18:46, 2123-10-10 14:18:46)                     164.0   \n",
       "         [2123-10-10 14:18:46, 2123-10-10 15:18:46)                     164.0   \n",
       "         [2123-10-10 15:18:46, 2123-10-10 16:18:46)                     164.0   \n",
       "         [2123-10-10 16:18:46, 2123-10-10 17:18:46)                     164.0   \n",
       "\n",
       "                                                     asparate_aminotransferase  \\\n",
       "stay_id  time                                                                    \n",
       "30004811 [2139-10-06 10:40:29, 2139-10-06 11:40:29)                       40.0   \n",
       "         [2139-10-06 11:40:29, 2139-10-06 12:40:29)                       40.0   \n",
       "         [2139-10-06 12:40:29, 2139-10-06 13:40:29)                       40.0   \n",
       "         [2139-10-06 13:40:29, 2139-10-06 14:40:29)                       40.0   \n",
       "         [2139-10-06 14:40:29, 2139-10-06 15:40:29)                       40.0   \n",
       "...                                                                        ...   \n",
       "39986775 [2123-10-10 12:18:46, 2123-10-10 13:18:46)                      240.0   \n",
       "         [2123-10-10 13:18:46, 2123-10-10 14:18:46)                      240.0   \n",
       "         [2123-10-10 14:18:46, 2123-10-10 15:18:46)                      240.0   \n",
       "         [2123-10-10 15:18:46, 2123-10-10 16:18:46)                      240.0   \n",
       "         [2123-10-10 16:18:46, 2123-10-10 17:18:46)                      240.0   \n",
       "\n",
       "                                                     mean_blood_pressure  \\\n",
       "stay_id  time                                                              \n",
       "30004811 [2139-10-06 10:40:29, 2139-10-06 11:40:29)                 77.0   \n",
       "         [2139-10-06 11:40:29, 2139-10-06 12:40:29)                 77.0   \n",
       "         [2139-10-06 12:40:29, 2139-10-06 13:40:29)                 77.0   \n",
       "         [2139-10-06 13:40:29, 2139-10-06 14:40:29)                 77.0   \n",
       "         [2139-10-06 14:40:29, 2139-10-06 15:40:29)                 77.0   \n",
       "...                                                                  ...   \n",
       "39986775 [2123-10-10 12:18:46, 2123-10-10 13:18:46)                 53.0   \n",
       "         [2123-10-10 13:18:46, 2123-10-10 14:18:46)                 67.0   \n",
       "         [2123-10-10 14:18:46, 2123-10-10 15:18:46)                 61.0   \n",
       "         [2123-10-10 15:18:46, 2123-10-10 16:18:46)                 67.0   \n",
       "         [2123-10-10 16:18:46, 2123-10-10 17:18:46)                 59.0   \n",
       "\n",
       "                                                     diastolic_blood_pressure  \\\n",
       "stay_id  time                                                                   \n",
       "30004811 [2139-10-06 10:40:29, 2139-10-06 11:40:29)                      59.0   \n",
       "         [2139-10-06 11:40:29, 2139-10-06 12:40:29)                      59.0   \n",
       "         [2139-10-06 12:40:29, 2139-10-06 13:40:29)                      59.0   \n",
       "         [2139-10-06 13:40:29, 2139-10-06 14:40:29)                      59.0   \n",
       "         [2139-10-06 14:40:29, 2139-10-06 15:40:29)                      59.0   \n",
       "...                                                                       ...   \n",
       "39986775 [2123-10-10 12:18:46, 2123-10-10 13:18:46)                      39.0   \n",
       "         [2123-10-10 13:18:46, 2123-10-10 14:18:46)                      47.0   \n",
       "         [2123-10-10 14:18:46, 2123-10-10 15:18:46)                      48.0   \n",
       "         [2123-10-10 15:18:46, 2123-10-10 16:18:46)                      55.0   \n",
       "         [2123-10-10 16:18:46, 2123-10-10 17:18:46)                      44.0   \n",
       "\n",
       "                                                     systolic_blood_pressure  \\\n",
       "stay_id  time                                                                  \n",
       "30004811 [2139-10-06 10:40:29, 2139-10-06 11:40:29)                    118.0   \n",
       "         [2139-10-06 11:40:29, 2139-10-06 12:40:29)                    118.0   \n",
       "         [2139-10-06 12:40:29, 2139-10-06 13:40:29)                    118.0   \n",
       "         [2139-10-06 13:40:29, 2139-10-06 14:40:29)                    118.0   \n",
       "         [2139-10-06 14:40:29, 2139-10-06 15:40:29)                    118.0   \n",
       "...                                                                      ...   \n",
       "39986775 [2123-10-10 12:18:46, 2123-10-10 13:18:46)                     81.0   \n",
       "         [2123-10-10 13:18:46, 2123-10-10 14:18:46)                    117.0   \n",
       "         [2123-10-10 14:18:46, 2123-10-10 15:18:46)                     97.0   \n",
       "         [2123-10-10 15:18:46, 2123-10-10 16:18:46)                    101.0   \n",
       "         [2123-10-10 16:18:46, 2123-10-10 17:18:46)                     90.0   \n",
       "\n",
       "                                                      gcs  \\\n",
       "stay_id  time                                               \n",
       "30004811 [2139-10-06 10:40:29, 2139-10-06 11:40:29)  11.0   \n",
       "         [2139-10-06 11:40:29, 2139-10-06 12:40:29)  11.0   \n",
       "         [2139-10-06 12:40:29, 2139-10-06 13:40:29)  11.0   \n",
       "         [2139-10-06 13:40:29, 2139-10-06 14:40:29)  11.0   \n",
       "         [2139-10-06 14:40:29, 2139-10-06 15:40:29)  11.0   \n",
       "...                                                   ...   \n",
       "39986775 [2123-10-10 12:18:46, 2123-10-10 13:18:46)  15.0   \n",
       "         [2123-10-10 13:18:46, 2123-10-10 14:18:46)  15.0   \n",
       "         [2123-10-10 14:18:46, 2123-10-10 15:18:46)  15.0   \n",
       "         [2123-10-10 15:18:46, 2123-10-10 16:18:46)  15.0   \n",
       "         [2123-10-10 16:18:46, 2123-10-10 17:18:46)  15.0   \n",
       "\n",
       "                                                     partial_pressure_of_oxygen  \\\n",
       "stay_id  time                                                                     \n",
       "30004811 [2139-10-06 10:40:29, 2139-10-06 11:40:29)                       112.0   \n",
       "         [2139-10-06 11:40:29, 2139-10-06 12:40:29)                       112.0   \n",
       "         [2139-10-06 12:40:29, 2139-10-06 13:40:29)                       272.0   \n",
       "         [2139-10-06 13:40:29, 2139-10-06 14:40:29)                       272.0   \n",
       "         [2139-10-06 14:40:29, 2139-10-06 15:40:29)                       272.0   \n",
       "...                                                                         ...   \n",
       "39986775 [2123-10-10 12:18:46, 2123-10-10 13:18:46)                        90.0   \n",
       "         [2123-10-10 13:18:46, 2123-10-10 14:18:46)                        90.0   \n",
       "         [2123-10-10 14:18:46, 2123-10-10 15:18:46)                        45.0   \n",
       "         [2123-10-10 15:18:46, 2123-10-10 16:18:46)                        50.0   \n",
       "         [2123-10-10 16:18:46, 2123-10-10 17:18:46)                        50.0   \n",
       "\n",
       "                                                     heart_rate  temperature  \\\n",
       "stay_id  time                                                                  \n",
       "30004811 [2139-10-06 10:40:29, 2139-10-06 11:40:29)        86.0    37.000000   \n",
       "         [2139-10-06 11:40:29, 2139-10-06 12:40:29)        86.0    37.000000   \n",
       "         [2139-10-06 12:40:29, 2139-10-06 13:40:29)        86.0    37.000000   \n",
       "         [2139-10-06 13:40:29, 2139-10-06 14:40:29)        86.0    37.000000   \n",
       "         [2139-10-06 14:40:29, 2139-10-06 15:40:29)        86.0    37.000000   \n",
       "...                                                         ...          ...   \n",
       "39986775 [2123-10-10 12:18:46, 2123-10-10 13:18:46)        81.0    36.833333   \n",
       "         [2123-10-10 13:18:46, 2123-10-10 14:18:46)        69.0    36.833333   \n",
       "         [2123-10-10 14:18:46, 2123-10-10 15:18:46)        88.0    36.833333   \n",
       "         [2123-10-10 15:18:46, 2123-10-10 16:18:46)        95.0    36.777778   \n",
       "         [2123-10-10 16:18:46, 2123-10-10 17:18:46)        87.0    36.777778   \n",
       "\n",
       "                                                     respiratory_rate  \n",
       "stay_id  time                                                          \n",
       "30004811 [2139-10-06 10:40:29, 2139-10-06 11:40:29)              19.0  \n",
       "         [2139-10-06 11:40:29, 2139-10-06 12:40:29)              19.0  \n",
       "         [2139-10-06 12:40:29, 2139-10-06 13:40:29)              19.0  \n",
       "         [2139-10-06 13:40:29, 2139-10-06 14:40:29)              19.0  \n",
       "         [2139-10-06 14:40:29, 2139-10-06 15:40:29)              19.0  \n",
       "...                                                               ...  \n",
       "39986775 [2123-10-10 12:18:46, 2123-10-10 13:18:46)              18.0  \n",
       "         [2123-10-10 13:18:46, 2123-10-10 14:18:46)              16.0  \n",
       "         [2123-10-10 14:18:46, 2123-10-10 15:18:46)              22.0  \n",
       "         [2123-10-10 15:18:46, 2123-10-10 16:18:46)              29.0  \n",
       "         [2123-10-10 16:18:46, 2123-10-10 17:18:46)              21.0  \n",
       "\n",
       "[355504 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_non_normailzed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "leawZNSQoOQz"
   },
   "source": [
    "**Run clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "id": "C2zygqxVtea3",
    "outputId": "1156a093-9123-44eb-9833-3ef0ce5aae3c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkjm/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=100, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=100, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=100, random_state=0)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K-Means\n",
    "num_clusters = 100\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
    "kmeans.fit(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN\n",
    "#db = DBSCAN(eps=0.3, min_samples=10).fit(X)\n",
    "#core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "#core_samples_mask[db.core_sample_indices_] = True\n",
    "#labels = db.labels_\n",
    " \n",
    "# Number of clusters in labels, ignoring noise if present\n",
    "# num_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IL3IkuIRPrta",
    "outputId": "065bb93f-9caa-42b9-c2c7-35816885c63c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14726,   469,   929,   275,   179,   401,  3514, 12641,    94,\n",
       "         983,  1070,   810,   374,   649,  9997,  1423,  3834,  9217,\n",
       "         302,   131,  6673,  7645, 11232,  3985,  1834, 18439,  2072,\n",
       "          18,    47,    82,  7912,   863,   146,  3929,  2567,   877,\n",
       "        3947,  1329,  2434,  1729,  9512,    48,  4349,  8987,  7392,\n",
       "       15238,   474,  8941,  3456,   596,   501,   664,   310,  5975,\n",
       "       10030,   304, 14225,   163,   322,   931,   308,    48,  1363,\n",
       "        5240, 11085,   309,   373,  6874,   587,   345,   187,   288,\n",
       "         459,  2022, 18926,  1003,  4219,  4252,  8135,   229,   418,\n",
       "        8573,  1803,  4790, 10018,  3207,  2571,  1447,   579,   116,\n",
       "        3484,   465,  2750,   114,  5453,   159,   433,  1002,   928,\n",
       "        8746])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(kmeans.labels_, return_counts=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "id": "rB-K_Pq5PuKd"
   },
   "outputs": [],
   "source": [
    "# Assigning each data point to a cluster\n",
    "X_df['cluster'] = kmeans.labels_.copy()\n",
    "data_df['cluster'] = kmeans.labels_.copy()\n",
    "data_non_normalized_df['cluster'] = kmeans.labels_.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxyUQWpX6eOz"
   },
   "source": [
    "**Create trajectories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "id": "OLcI66h9P1cN"
   },
   "outputs": [],
   "source": [
    "unique_stay_ids = data_df.index.get_level_values('stay_id').unique()\n",
    "\n",
    "trajectories = []\n",
    "\n",
    "\n",
    "for stay_id in unique_stay_ids:\n",
    "\n",
    "\n",
    "  states, actions = data_df.loc[stay_id]['cluster'], data_df.loc[stay_id]['action']\n",
    "\n",
    "  trajectory = []\n",
    "  for i in range(len(states) - 1):\n",
    "    trajectory.append((states[i], int(actions[i]), states[i+1] ))\n",
    "\n",
    "  trajectories.append(T.Trajectory(trajectory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QRpR2QI75-3"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "id": "fml7yGVoP6Nh"
   },
   "outputs": [],
   "source": [
    "terminal_states = []\n",
    "\n",
    "for traj in trajectories:\n",
    "  terminal_states.append(traj._t[-1][-1])\n",
    "\n",
    "terminal_states = list(set(terminal_states))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_gO7Id4nhDw"
   },
   "source": [
    "**Calculate Transition Probabilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "id": "Tmn1Uw98QUxP"
   },
   "outputs": [],
   "source": [
    "smoothing_value = 1\n",
    "\n",
    "p_transition = np.zeros((num_clusters, num_clusters, 4)) + smoothing_value\n",
    "\n",
    "\n",
    "for traj in trajectories:\n",
    "\n",
    "  for tran in traj._t:\n",
    "                 #     s,      s',      a\n",
    "    p_transition[tran[0], tran[2], tran[1]] +=1\n",
    "\n",
    "p_transition = p_transition/ p_transition.sum(axis = 1)[:, np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "2r_UQo3k2GZl"
   },
   "outputs": [],
   "source": [
    "# our existing p_transition matrix is shaped [s][s'][a]\n",
    "# We need to swap the axes to get [s][a][s'] for the FIRL algorithm input\n",
    "\n",
    "# Swap the axes of p_transition to match the expected order\n",
    "sa_p = np.swapaxes(p_transition, 1, 2)\n",
    "\n",
    "# Now sa_p is in the shape [state][action][target state] as requiredb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dQ8GqvIc_gUo",
    "outputId": "0133d560-80f5-491f-a3f5-cfa851e7af04",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4, 100)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "id": "fLJYLcx62Gib"
   },
   "outputs": [],
   "source": [
    "def build_mdp_data(states, actions, discount, sa_p):\n",
    "    # Number of states (clusters) and actions are given\n",
    "\n",
    "    # Initialize sa_s as a 3D array where sa_s[s, a, :] contains all possible next states\n",
    "    # for taking action 'a' in state 's'\n",
    "    sa_s = np.zeros((states, actions, states), dtype=int)\n",
    "\n",
    "    # Here, we'll fill in sa_s with the indices of potential successor states.\n",
    "    # This is a simplification for demonstration and should be tailored to your actual environment.\n",
    "    for s in range(states):\n",
    "        for a in range(actions):\n",
    "            # The successor states are assumed to be all other states, including the current state.\n",
    "            # This means from any state 's', any action 'a' can potentially lead to any state.\n",
    "            sa_s[s, a, :] = np.arange(states)\n",
    "\n",
    "    # Create MDP data structure\n",
    "    mdp_data = {\n",
    "        'states': states,\n",
    "        'actions': actions,\n",
    "        'discount': discount,\n",
    "        'sa_s': sa_s,\n",
    "        'sa_p': sa_p\n",
    "    }\n",
    "\n",
    "    return mdp_data\n",
    "\n",
    "# Example usage:\n",
    "num_states = num_clusters  # Number of states\n",
    "num_actions = sa_p.shape[1]  # In our case 4 possible actions (vaso, etc.)\n",
    "discount = 0.9      # Discount factor for MDP\n",
    "\n",
    "mdp_data = build_mdp_data(num_states, num_actions, discount, sa_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_qN_RHgf2GmQ",
    "outputId": "2b60e389-8dd4-49d7-83a8-26ea00987f46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'states': 100, 'actions': 4, 'discount': 0.9, 'sa_s': array([[[ 0,  1,  2, ..., 97, 98, 99],\n",
      "        [ 0,  1,  2, ..., 97, 98, 99],\n",
      "        [ 0,  1,  2, ..., 97, 98, 99],\n",
      "        [ 0,  1,  2, ..., 97, 98, 99]],\n",
      "\n",
      "       [[ 0,  1,  2, ..., 97, 98, 99],\n",
      "        [ 0,  1,  2, ..., 97, 98, 99],\n",
      "        [ 0,  1,  2, ..., 97, 98, 99],\n",
      "        [ 0,  1,  2, ..., 97, 98, 99]],\n",
      "\n",
      "       [[ 0,  1,  2, ..., 97, 98, 99],\n",
      "        [ 0,  1,  2, ..., 97, 98, 99],\n",
      "        [ 0,  1,  2, ..., 97, 98, 99],\n",
      "        [ 0,  1,  2, ..., 97, 98, 99]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0,  1,  2, ..., 97, 98, 99],\n",
      "        [ 0,  1,  2, ..., 97, 98, 99],\n",
      "        [ 0,  1,  2, ..., 97, 98, 99],\n",
      "        [ 0,  1,  2, ..., 97, 98, 99]],\n",
      "\n",
      "       [[ 0,  1,  2, ..., 97, 98, 99],\n",
      "        [ 0,  1,  2, ..., 97, 98, 99],\n",
      "        [ 0,  1,  2, ..., 97, 98, 99],\n",
      "        [ 0,  1,  2, ..., 97, 98, 99]],\n",
      "\n",
      "       [[ 0,  1,  2, ..., 97, 98, 99],\n",
      "        [ 0,  1,  2, ..., 97, 98, 99],\n",
      "        [ 0,  1,  2, ..., 97, 98, 99],\n",
      "        [ 0,  1,  2, ..., 97, 98, 99]]]), 'sa_p': array([[[4.60893345e-01, 9.11577028e-05, 9.11577028e-05, ...,\n",
      "         9.11577028e-05, 9.11577028e-05, 2.18778487e-03],\n",
      "        [3.20431472e-01, 3.17258883e-04, 3.17258883e-04, ...,\n",
      "         3.17258883e-04, 3.17258883e-04, 1.90355330e-03],\n",
      "        [2.29885057e-01, 2.87356322e-03, 2.87356322e-03, ...,\n",
      "         2.87356322e-03, 2.87356322e-03, 2.87356322e-03],\n",
      "        [1.60771704e-01, 3.21543408e-03, 3.21543408e-03, ...,\n",
      "         3.21543408e-03, 3.21543408e-03, 3.21543408e-03]],\n",
      "\n",
      "       [[2.39234450e-03, 7.58373206e-01, 2.39234450e-03, ...,\n",
      "         2.39234450e-03, 2.39234450e-03, 2.39234450e-03],\n",
      "        [4.73933649e-03, 5.16587678e-01, 4.73933649e-03, ...,\n",
      "         4.73933649e-03, 4.73933649e-03, 4.73933649e-03],\n",
      "        [8.54700855e-03, 1.53846154e-01, 8.54700855e-03, ...,\n",
      "         8.54700855e-03, 8.54700855e-03, 8.54700855e-03],\n",
      "        [8.62068966e-03, 1.46551724e-01, 8.62068966e-03, ...,\n",
      "         8.62068966e-03, 8.62068966e-03, 8.62068966e-03]],\n",
      "\n",
      "       [[1.69204738e-03, 1.69204738e-03, 8.03722504e-01, ...,\n",
      "         1.69204738e-03, 1.69204738e-03, 1.69204738e-03],\n",
      "        [2.08768267e-03, 2.08768267e-03, 7.36951983e-01, ...,\n",
      "         6.26304802e-03, 2.08768267e-03, 2.08768267e-03],\n",
      "        [8.62068966e-03, 8.62068966e-03, 1.46551724e-01, ...,\n",
      "         8.62068966e-03, 8.62068966e-03, 8.62068966e-03],\n",
      "        [7.63358779e-03, 7.63358779e-03, 2.29007634e-01, ...,\n",
      "         7.63358779e-03, 7.63358779e-03, 7.63358779e-03]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[2.01207243e-03, 2.01207243e-03, 6.03621730e-03, ...,\n",
      "         7.80684105e-01, 2.01207243e-03, 2.01207243e-03],\n",
      "        [1.60771704e-03, 1.60771704e-03, 3.21543408e-03, ...,\n",
      "         8.02250804e-01, 3.21543408e-03, 3.21543408e-03],\n",
      "        [8.69565217e-03, 8.69565217e-03, 1.73913043e-02, ...,\n",
      "         1.21739130e-01, 8.69565217e-03, 8.69565217e-03],\n",
      "        [6.62251656e-03, 6.62251656e-03, 6.62251656e-03, ...,\n",
      "         3.44370861e-01, 6.62251656e-03, 6.62251656e-03]],\n",
      "\n",
      "       [[2.16919740e-03, 2.16919740e-03, 2.16919740e-03, ...,\n",
      "         2.16919740e-03, 7.61388286e-01, 2.16919740e-03],\n",
      "        [1.82481752e-03, 1.82481752e-03, 1.82481752e-03, ...,\n",
      "         1.82481752e-03, 7.81021898e-01, 1.82481752e-03],\n",
      "        [8.40336134e-03, 8.40336134e-03, 8.40336134e-03, ...,\n",
      "         8.40336134e-03, 1.68067227e-01, 8.40336134e-03],\n",
      "        [5.34759358e-03, 5.34759358e-03, 5.34759358e-03, ...,\n",
      "         5.34759358e-03, 4.59893048e-01, 5.34759358e-03]],\n",
      "\n",
      "       [[2.15924426e-03, 2.69905533e-04, 2.69905533e-04, ...,\n",
      "         2.69905533e-04, 2.69905533e-04, 5.98110661e-01],\n",
      "        [1.56494523e-03, 2.23563604e-04, 2.23563604e-04, ...,\n",
      "         2.23563604e-04, 2.23563604e-04, 6.74491393e-01],\n",
      "        [3.11526480e-03, 3.11526480e-03, 3.11526480e-03, ...,\n",
      "         3.11526480e-03, 3.11526480e-03, 4.36137072e-01],\n",
      "        [3.64298725e-03, 1.82149362e-03, 1.82149362e-03, ...,\n",
      "         1.82149362e-03, 1.82149362e-03, 5.35519126e-01]]])}\n"
     ]
    }
   ],
   "source": [
    "print(mdp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "fTREVS9a2GuN",
    "outputId": "d94db5a4-475f-40ce-9a1c-19dc047179f4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creatinine</th>\n",
       "      <th>fraction_inspired_oxygen</th>\n",
       "      <th>lactate</th>\n",
       "      <th>urine_output</th>\n",
       "      <th>alanine_aminotransferase</th>\n",
       "      <th>asparate_aminotransferase</th>\n",
       "      <th>mean_blood_pressure</th>\n",
       "      <th>diastolic_blood_pressure</th>\n",
       "      <th>systolic_blood_pressure</th>\n",
       "      <th>gcs</th>\n",
       "      <th>...</th>\n",
       "      <th>asparate_aminotransferase_binned_binned_binned</th>\n",
       "      <th>mean_blood_pressure_binned_binned_binned</th>\n",
       "      <th>diastolic_blood_pressure_binned_binned_binned</th>\n",
       "      <th>systolic_blood_pressure_binned_binned_binned</th>\n",
       "      <th>gcs_binned_binned_binned</th>\n",
       "      <th>partial_pressure_of_oxygen_binned_binned_binned</th>\n",
       "      <th>heart_rate_binned_binned_binned</th>\n",
       "      <th>temperature_binned_binned_binned</th>\n",
       "      <th>respiratory_rate_binned_binned_binned</th>\n",
       "      <th>cluster_binned_binned_binned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.422008</td>\n",
       "      <td>-1.760743</td>\n",
       "      <td>-0.182521</td>\n",
       "      <td>-0.225783</td>\n",
       "      <td>-0.288689</td>\n",
       "      <td>-0.265706</td>\n",
       "      <td>0.404836</td>\n",
       "      <td>0.391566</td>\n",
       "      <td>0.368850</td>\n",
       "      <td>-2.479374</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>170</td>\n",
       "      <td>166</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>136</td>\n",
       "      <td>571</td>\n",
       "      <td>83</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.422008</td>\n",
       "      <td>-1.760743</td>\n",
       "      <td>-0.182521</td>\n",
       "      <td>-0.225783</td>\n",
       "      <td>-0.288689</td>\n",
       "      <td>-0.265706</td>\n",
       "      <td>0.404836</td>\n",
       "      <td>0.391566</td>\n",
       "      <td>0.368850</td>\n",
       "      <td>-2.479374</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>170</td>\n",
       "      <td>166</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>136</td>\n",
       "      <td>571</td>\n",
       "      <td>83</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.422008</td>\n",
       "      <td>-1.760743</td>\n",
       "      <td>0.360532</td>\n",
       "      <td>-0.225783</td>\n",
       "      <td>-0.288689</td>\n",
       "      <td>-0.265706</td>\n",
       "      <td>0.404836</td>\n",
       "      <td>0.391566</td>\n",
       "      <td>0.368850</td>\n",
       "      <td>-2.479374</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>170</td>\n",
       "      <td>166</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>136</td>\n",
       "      <td>571</td>\n",
       "      <td>83</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.422008</td>\n",
       "      <td>-1.760743</td>\n",
       "      <td>0.360532</td>\n",
       "      <td>-0.225783</td>\n",
       "      <td>-0.288689</td>\n",
       "      <td>-0.265706</td>\n",
       "      <td>0.404836</td>\n",
       "      <td>0.391566</td>\n",
       "      <td>0.368850</td>\n",
       "      <td>-2.479374</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>170</td>\n",
       "      <td>166</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>136</td>\n",
       "      <td>571</td>\n",
       "      <td>83</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.422008</td>\n",
       "      <td>-1.760743</td>\n",
       "      <td>0.360532</td>\n",
       "      <td>-0.225783</td>\n",
       "      <td>-0.288689</td>\n",
       "      <td>-0.265706</td>\n",
       "      <td>0.404836</td>\n",
       "      <td>0.391566</td>\n",
       "      <td>0.368850</td>\n",
       "      <td>-2.479374</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>170</td>\n",
       "      <td>166</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>136</td>\n",
       "      <td>571</td>\n",
       "      <td>83</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355499</th>\n",
       "      <td>0.739524</td>\n",
       "      <td>-0.606278</td>\n",
       "      <td>-0.273030</td>\n",
       "      <td>0.138982</td>\n",
       "      <td>-0.080898</td>\n",
       "      <td>-0.123953</td>\n",
       "      <td>-1.457422</td>\n",
       "      <td>-1.418182</td>\n",
       "      <td>-1.615710</td>\n",
       "      <td>0.229732</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>105</td>\n",
       "      <td>109</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>128</td>\n",
       "      <td>562</td>\n",
       "      <td>77</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355500</th>\n",
       "      <td>0.739524</td>\n",
       "      <td>-0.606278</td>\n",
       "      <td>-0.273030</td>\n",
       "      <td>-0.387901</td>\n",
       "      <td>-0.080898</td>\n",
       "      <td>-0.123953</td>\n",
       "      <td>-0.371105</td>\n",
       "      <td>-0.694283</td>\n",
       "      <td>0.315214</td>\n",
       "      <td>0.229732</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>142</td>\n",
       "      <td>132</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>110</td>\n",
       "      <td>562</td>\n",
       "      <td>68</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355501</th>\n",
       "      <td>0.739524</td>\n",
       "      <td>-0.606278</td>\n",
       "      <td>-0.499303</td>\n",
       "      <td>-0.550019</td>\n",
       "      <td>-0.080898</td>\n",
       "      <td>-0.123953</td>\n",
       "      <td>-0.836669</td>\n",
       "      <td>-0.603795</td>\n",
       "      <td>-0.757522</td>\n",
       "      <td>0.229732</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>126</td>\n",
       "      <td>134</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>139</td>\n",
       "      <td>562</td>\n",
       "      <td>96</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355502</th>\n",
       "      <td>0.739524</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>-0.544557</td>\n",
       "      <td>-0.550019</td>\n",
       "      <td>-0.080898</td>\n",
       "      <td>-0.123953</td>\n",
       "      <td>-0.371105</td>\n",
       "      <td>0.029617</td>\n",
       "      <td>-0.542975</td>\n",
       "      <td>0.229732</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>142</td>\n",
       "      <td>153</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>152</td>\n",
       "      <td>559</td>\n",
       "      <td>126</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355503</th>\n",
       "      <td>0.739524</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>-0.544557</td>\n",
       "      <td>-0.550019</td>\n",
       "      <td>-0.080898</td>\n",
       "      <td>-0.123953</td>\n",
       "      <td>-0.991858</td>\n",
       "      <td>-0.965745</td>\n",
       "      <td>-1.132979</td>\n",
       "      <td>0.229732</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>121</td>\n",
       "      <td>123</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>138</td>\n",
       "      <td>559</td>\n",
       "      <td>92</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>355504 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        creatinine  fraction_inspired_oxygen   lactate  urine_output  \\\n",
       "0        -0.422008                 -1.760743 -0.182521     -0.225783   \n",
       "1        -0.422008                 -1.760743 -0.182521     -0.225783   \n",
       "2        -0.422008                 -1.760743  0.360532     -0.225783   \n",
       "3        -0.422008                 -1.760743  0.360532     -0.225783   \n",
       "4        -0.422008                 -1.760743  0.360532     -0.225783   \n",
       "...            ...                       ...       ...           ...   \n",
       "355499    0.739524                 -0.606278 -0.273030      0.138982   \n",
       "355500    0.739524                 -0.606278 -0.273030     -0.387901   \n",
       "355501    0.739524                 -0.606278 -0.499303     -0.550019   \n",
       "355502    0.739524                  0.001335 -0.544557     -0.550019   \n",
       "355503    0.739524                  0.001335 -0.544557     -0.550019   \n",
       "\n",
       "        alanine_aminotransferase  asparate_aminotransferase  \\\n",
       "0                      -0.288689                  -0.265706   \n",
       "1                      -0.288689                  -0.265706   \n",
       "2                      -0.288689                  -0.265706   \n",
       "3                      -0.288689                  -0.265706   \n",
       "4                      -0.288689                  -0.265706   \n",
       "...                          ...                        ...   \n",
       "355499                 -0.080898                  -0.123953   \n",
       "355500                 -0.080898                  -0.123953   \n",
       "355501                 -0.080898                  -0.123953   \n",
       "355502                 -0.080898                  -0.123953   \n",
       "355503                 -0.080898                  -0.123953   \n",
       "\n",
       "        mean_blood_pressure  diastolic_blood_pressure  \\\n",
       "0                  0.404836                  0.391566   \n",
       "1                  0.404836                  0.391566   \n",
       "2                  0.404836                  0.391566   \n",
       "3                  0.404836                  0.391566   \n",
       "4                  0.404836                  0.391566   \n",
       "...                     ...                       ...   \n",
       "355499            -1.457422                 -1.418182   \n",
       "355500            -0.371105                 -0.694283   \n",
       "355501            -0.836669                 -0.603795   \n",
       "355502            -0.371105                  0.029617   \n",
       "355503            -0.991858                 -0.965745   \n",
       "\n",
       "        systolic_blood_pressure       gcs  ...  \\\n",
       "0                      0.368850 -2.479374  ...   \n",
       "1                      0.368850 -2.479374  ...   \n",
       "2                      0.368850 -2.479374  ...   \n",
       "3                      0.368850 -2.479374  ...   \n",
       "4                      0.368850 -2.479374  ...   \n",
       "...                         ...       ...  ...   \n",
       "355499                -1.615710  0.229732  ...   \n",
       "355500                 0.315214  0.229732  ...   \n",
       "355501                -0.757522  0.229732  ...   \n",
       "355502                -0.542975  0.229732  ...   \n",
       "355503                -1.132979  0.229732  ...   \n",
       "\n",
       "        asparate_aminotransferase_binned_binned_binned  \\\n",
       "0                                                    7   \n",
       "1                                                    7   \n",
       "2                                                    7   \n",
       "3                                                    7   \n",
       "4                                                    7   \n",
       "...                                                ...   \n",
       "355499                                              63   \n",
       "355500                                              63   \n",
       "355501                                              63   \n",
       "355502                                              63   \n",
       "355503                                              63   \n",
       "\n",
       "        mean_blood_pressure_binned_binned_binned  \\\n",
       "0                                            170   \n",
       "1                                            170   \n",
       "2                                            170   \n",
       "3                                            170   \n",
       "4                                            170   \n",
       "...                                          ...   \n",
       "355499                                       105   \n",
       "355500                                       142   \n",
       "355501                                       126   \n",
       "355502                                       142   \n",
       "355503                                       121   \n",
       "\n",
       "        diastolic_blood_pressure_binned_binned_binned  \\\n",
       "0                                                 166   \n",
       "1                                                 166   \n",
       "2                                                 166   \n",
       "3                                                 166   \n",
       "4                                                 166   \n",
       "...                                               ...   \n",
       "355499                                            109   \n",
       "355500                                            132   \n",
       "355501                                            134   \n",
       "355502                                            153   \n",
       "355503                                            123   \n",
       "\n",
       "        systolic_blood_pressure_binned_binned_binned  \\\n",
       "0                                                185   \n",
       "1                                                185   \n",
       "2                                                185   \n",
       "3                                                185   \n",
       "4                                                185   \n",
       "...                                              ...   \n",
       "355499                                           126   \n",
       "355500                                           184   \n",
       "355501                                           153   \n",
       "355502                                           159   \n",
       "355503                                           140   \n",
       "\n",
       "        gcs_binned_binned_binned  \\\n",
       "0                              0   \n",
       "1                              0   \n",
       "2                              0   \n",
       "3                              0   \n",
       "4                              0   \n",
       "...                          ...   \n",
       "355499                         0   \n",
       "355500                         0   \n",
       "355501                         0   \n",
       "355502                         0   \n",
       "355503                         0   \n",
       "\n",
       "        partial_pressure_of_oxygen_binned_binned_binned  \\\n",
       "0                                                    48   \n",
       "1                                                    48   \n",
       "2                                                   147   \n",
       "3                                                   147   \n",
       "4                                                   147   \n",
       "...                                                 ...   \n",
       "355499                                               35   \n",
       "355500                                               35   \n",
       "355501                                                7   \n",
       "355502                                               10   \n",
       "355503                                               10   \n",
       "\n",
       "        heart_rate_binned_binned_binned  temperature_binned_binned_binned  \\\n",
       "0                                   136                               571   \n",
       "1                                   136                               571   \n",
       "2                                   136                               571   \n",
       "3                                   136                               571   \n",
       "4                                   136                               571   \n",
       "...                                 ...                               ...   \n",
       "355499                              128                               562   \n",
       "355500                              110                               562   \n",
       "355501                              139                               562   \n",
       "355502                              152                               559   \n",
       "355503                              138                               559   \n",
       "\n",
       "        respiratory_rate_binned_binned_binned  cluster_binned_binned_binned  \n",
       "0                                          83                             8  \n",
       "1                                          83                             8  \n",
       "2                                          83                            34  \n",
       "3                                          83                            34  \n",
       "4                                          83                            34  \n",
       "...                                       ...                           ...  \n",
       "355499                                     77                            71  \n",
       "355500                                     68                            71  \n",
       "355501                                     96                            71  \n",
       "355502                                    126                            71  \n",
       "355503                                     92                            71  \n",
       "\n",
       "[355504 rows x 60 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCVkWkDFh0gI"
   },
   "source": [
    "## We now discretize each column separately\n",
    "We need to do this since FIRL expects binary encoded features (for each\n",
    "state, or in our case: cluster\n",
    "\n",
    "We experimented with two approaches:\n",
    "- binning (i.e. like in a histogram)\n",
    "and more specifically using the Freedman-Diaconis rule for bin width\n",
    "- 1D clustering using the Fisher-Jenks algorithm\n",
    "\n",
    "Our intuition (+ hopefully experiments will show) is that the latter approach performs better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kTAYumG-iUxI",
    "outputId": "bdc57914-b8f9-4941-bfb4-d25919efd18e"
   },
   "outputs": [],
   "source": [
    "# We make use of the package which comes with an efficient C implementation of the algo\n",
    "#!pip install -q jenkspy\n",
    "#import jenkspy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OhsIYg9ilwR"
   },
   "source": [
    "<b>Binning approach</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "id": "z1K1zF4y2Gyn"
   },
   "outputs": [],
   "source": [
    "bin_edges_dict = {}\n",
    "\n",
    "# Discretize each column separately\n",
    "for column in X_df.columns:\n",
    "    # REVIEW:\n",
    "    # Calculate the bin width using the Freedman-Diaconis rule\n",
    "    q75, q25 = np.percentile(X_df[column].dropna(), [75, 25])\n",
    "    iqr = q75 - q25\n",
    "    bin_width = 2 * iqr * (len(X_df[column]) ** (-1/3))\n",
    "\n",
    "    # Determine the range of the data\n",
    "    data_min, data_max = X_df[column].min(), X_df[column].max()\n",
    "\n",
    "    # Use numpy.histogram_bin_edges to get the bin edges\n",
    "    bin_edges = np.histogram_bin_edges(X_df[column].dropna(), bins='fd', range=(data_min, data_max))\n",
    "\n",
    "    bin_edges_dict[column + '_binned'] = bin_edges\n",
    "\n",
    "    # Discretize the column using the cut function and the bin edges\n",
    "    X_df[column + '_binned'] = pd.cut(X_df[column], bins=bin_edges, labels=False, include_lowest=True)\n",
    "\n",
    "# Now X_df has additional columns with the suffix '_binned' representing discretized values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "id": "n4kib4ii2G14"
   },
   "outputs": [],
   "source": [
    "# Create a new DataFrame with only the columns that have '_binned' suffix\n",
    "X_df_binned = X_df.filter(like='_binned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "anJUnIf0avDq",
    "outputId": "65ae6bcf-86e5-4532-ede2-edeacea117e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creatinine_binned                                          701\n",
      "fraction_inspired_oxygen_binned                            279\n",
      "lactate_binned                                             844\n",
      "urine_output_binned                                        438\n",
      "alanine_aminotransferase_binned                           4617\n",
      "asparate_aminotransferase_binned                          5655\n",
      "mean_blood_pressure_binned                                 860\n",
      "diastolic_blood_pressure_binned                            742\n",
      "systolic_blood_pressure_binned                             432\n",
      "gcs_binned                                                   0\n",
      "partial_pressure_of_oxygen_binned                          409\n",
      "heart_rate_binned                                          450\n",
      "temperature_binned                                         826\n",
      "respiratory_rate_binned                                   1328\n",
      "cluster_binned                                              68\n",
      "creatinine_binned_binned                                   709\n",
      "fraction_inspired_oxygen_binned_binned                     282\n",
      "lactate_binned_binned                                      830\n",
      "urine_output_binned_binned                                 443\n",
      "alanine_aminotransferase_binned_binned                    4542\n",
      "asparate_aminotransferase_binned_binned                   5563\n",
      "mean_blood_pressure_binned_binned                          870\n",
      "diastolic_blood_pressure_binned_binned                     730\n",
      "systolic_blood_pressure_binned_binned                      437\n",
      "gcs_binned_binned                                            0\n",
      "partial_pressure_of_oxygen_binned_binned                   402\n",
      "heart_rate_binned_binned                                   442\n",
      "temperature_binned_binned                                  835\n",
      "respiratory_rate_binned_binned                            1343\n",
      "cluster_binned_binned                                       68\n",
      "creatinine_binned_binned_binned                            717\n",
      "fraction_inspired_oxygen_binned_binned_binned              277\n",
      "lactate_binned_binned_binned                               816\n",
      "urine_output_binned_binned_binned                          448\n",
      "alanine_aminotransferase_binned_binned_binned             4468\n",
      "asparate_aminotransferase_binned_binned_binned            5473\n",
      "mean_blood_pressure_binned_binned_binned                   855\n",
      "diastolic_blood_pressure_binned_binned_binned              738\n",
      "systolic_blood_pressure_binned_binned_binned               442\n",
      "gcs_binned_binned_binned                                     0\n",
      "partial_pressure_of_oxygen_binned_binned_binned            406\n",
      "heart_rate_binned_binned_binned                            447\n",
      "temperature_binned_binned_binned                           845\n",
      "respiratory_rate_binned_binned_binned                     1321\n",
      "cluster_binned_binned_binned                                68\n",
      "creatinine_binned_binned_binned_binned                     725\n",
      "fraction_inspired_oxygen_binned_binned_binned_binned       280\n",
      "lactate_binned_binned_binned_binned                        802\n",
      "urine_output_binned_binned_binned_binned                   453\n",
      "alanine_aminotransferase_binned_binned_binned_binned      4396\n",
      "asparate_aminotransferase_binned_binned_binned_binned     5384\n",
      "mean_blood_pressure_binned_binned_binned_binned            841\n",
      "diastolic_blood_pressure_binned_binned_binned_binned       726\n",
      "systolic_blood_pressure_binned_binned_binned_binned        447\n",
      "gcs_binned_binned_binned_binned                              0\n",
      "partial_pressure_of_oxygen_binned_binned_binned_binned     410\n",
      "heart_rate_binned_binned_binned_binned                     439\n",
      "temperature_binned_binned_binned_binned                    855\n",
      "respiratory_rate_binned_binned_binned_binned              1299\n",
      "cluster_binned_binned_binned_binned                         68\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Examine the number of bins created per each column\n",
    "print(X_df_binned.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "id": "XoxZ2ZlXAAT1"
   },
   "outputs": [],
   "source": [
    "# For further processing, it will also be useful to know the specific bin boundaries\n",
    "# for each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjmjKpcBirtL"
   },
   "source": [
    "<b> 1D Clustering approach </b>\n",
    "\n",
    "   The result of the code is a DataFrame where each continuous variable is replaced by a discretized version, with the discretization determined by the natural breaks found by the Fisher-Jenks algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "U8aQKODbbSSv",
    "outputId": "03071e18-402a-4178-d1b6-720b1c9b1bc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis (or at least this implementation) turns out to be way too slow!\\n\\nfor column in X_df.columns:\\n    print(\"Processing column\", column)\\n    # Apply Fisher-Jenks algorithm to find natural breaks\\n    # The number of bins is still a hyperparameter based on domain knowledge\\n    num_bins = 2\\n    breaks = jenkspy.jenks_breaks(X_df[column].dropna(), n_classes=num_bins)\\n\\n    # Create a new column for the binned data\\n    X_df[column + \\'_clustered\\'] = pd.cut(X_df[column], bins=breaks, labels=range(num_bins), include_lowest=True)\\n\\n# Filter out the original columns to create a new DataFrame with only binned data\\nbinned_columns_X_df = X_df.filter(like=\\'_clustered\\')\\n'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This (or at least this implementation) turns out to be way too slow!\n",
    "\n",
    "for column in X_df.columns:\n",
    "    print(\"Processing column\", column)\n",
    "    # Apply Fisher-Jenks algorithm to find natural breaks\n",
    "    # The number of bins is still a hyperparameter based on domain knowledge\n",
    "    num_bins = 2\n",
    "    breaks = jenkspy.jenks_breaks(X_df[column].dropna(), n_classes=num_bins)\n",
    "\n",
    "    # Create a new column for the binned data\n",
    "    X_df[column + '_clustered'] = pd.cut(X_df[column], bins=breaks, labels=range(num_bins), include_lowest=True)\n",
    "\n",
    "# Filter out the original columns to create a new DataFrame with only binned data\n",
    "binned_columns_X_df = X_df.filter(like='_clustered')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "id": "B8nxUr6xqJPu"
   },
   "outputs": [],
   "source": [
    "# Individual cluster statistics\n",
    "df_clusters = pd.DataFrame()\n",
    "\n",
    "# We only examine the 5-95 percentiles for each cluster for the purposes of binary encoding\n",
    "# This is clumsy, need to clean this up\n",
    "# def percentile_5th(series):\n",
    "#     return np.percentile(series, 5)\n",
    "\n",
    "# def percentile_95th(series):\n",
    "#     return np.percentile(series, 95)\n",
    "\n",
    "TOP_PERCENTILE = 90     # 95\n",
    "BOTTOM_PERCENTILE = 10  # 5\n",
    "\n",
    "# For feature in the DataFrame (excluding the cluster_id)\n",
    "for feature in X_df.columns.difference(['cluster']):\n",
    "    # Group by 'cluster_id' and calculate the 10th and 90th percentiles for the feature\n",
    "    grouped = X_df.groupby('cluster')[feature].agg([lambda series: np.percentile(series, BOTTOM_PERCENTILE), lambda series: np.percentile(series, TOP_PERCENTILE)]).reset_index()\n",
    "\n",
    "    # Rename the columns appropriately\n",
    "    grouped.columns = ['cluster', f'{feature}_{BOTTOM_PERCENTILE}th_percentile', f'{feature}_{TOP_PERCENTILE}th_percentile']\n",
    "\n",
    "    # Merge the statistics back into the df_clusters DataFrame\n",
    "    if df_clusters.empty:\n",
    "        df_clusters = grouped\n",
    "    else:\n",
    "        df_clusters = pd.merge(df_clusters, grouped, on='cluster', how='outer')\n",
    "\n",
    "### TODO: remove\n",
    "# Previous code looked at the absolute [min, max] range\n",
    "# Iterate over each feature in the original DataFrame (excluding the cluster_id)\n",
    "# for feature in X_df.columns.difference(['cluster']):\n",
    "#     # Group by 'cluster_id' and calculate the mean, min, and max for the feature\n",
    "#     grouped = X_df.groupby('cluster')[feature].agg([np.mean, np.min, np.max]).reset_index()\n",
    "\n",
    "#     # rename\n",
    "#     grouped.columns = ['cluster', f'{feature}_mean', f'{feature}_min', f'{feature}_max']\n",
    "\n",
    "#     # Merge the stats back\n",
    "#     if df_clusters.empty:\n",
    "#         df_clusters = grouped\n",
    "#     else:\n",
    "#         df_clusters = pd.merge(df_clusters, grouped, on='cluster', how='outer')\n",
    "\n",
    "# Set the index to the cluster_id\n",
    "df_clusters.set_index('cluster', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "n-NRp4zc4g8V",
    "outputId": "47c131fa-f448-4f57-96da-78f5756ea8ed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alanine_aminotransferase_10th_percentile</th>\n",
       "      <th>alanine_aminotransferase_90th_percentile</th>\n",
       "      <th>alanine_aminotransferase_binned_10th_percentile</th>\n",
       "      <th>alanine_aminotransferase_binned_90th_percentile</th>\n",
       "      <th>alanine_aminotransferase_binned_binned_10th_percentile</th>\n",
       "      <th>alanine_aminotransferase_binned_binned_90th_percentile</th>\n",
       "      <th>alanine_aminotransferase_binned_binned_binned_10th_percentile</th>\n",
       "      <th>alanine_aminotransferase_binned_binned_binned_90th_percentile</th>\n",
       "      <th>alanine_aminotransferase_binned_binned_binned_binned_10th_percentile</th>\n",
       "      <th>alanine_aminotransferase_binned_binned_binned_binned_90th_percentile</th>\n",
       "      <th>...</th>\n",
       "      <th>urine_output_10th_percentile</th>\n",
       "      <th>urine_output_90th_percentile</th>\n",
       "      <th>urine_output_binned_10th_percentile</th>\n",
       "      <th>urine_output_binned_90th_percentile</th>\n",
       "      <th>urine_output_binned_binned_10th_percentile</th>\n",
       "      <th>urine_output_binned_binned_90th_percentile</th>\n",
       "      <th>urine_output_binned_binned_binned_10th_percentile</th>\n",
       "      <th>urine_output_binned_binned_binned_90th_percentile</th>\n",
       "      <th>urine_output_binned_binned_binned_binned_10th_percentile</th>\n",
       "      <th>urine_output_binned_binned_binned_binned_90th_percentile</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.329449</td>\n",
       "      <td>-0.229549</td>\n",
       "      <td>2.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.631078</td>\n",
       "      <td>0.746923</td>\n",
       "      <td>10.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.973042</td>\n",
       "      <td>2.436578</td>\n",
       "      <td>692.0</td>\n",
       "      <td>831.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>817.0</td>\n",
       "      <td>669.0</td>\n",
       "      <td>803.0</td>\n",
       "      <td>658.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.712137</td>\n",
       "      <td>0.746923</td>\n",
       "      <td>7.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.581435</td>\n",
       "      <td>2.145669</td>\n",
       "      <td>575.0</td>\n",
       "      <td>744.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>732.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>708.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.833725</td>\n",
       "      <td>1.152217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.643964</td>\n",
       "      <td>5.344062</td>\n",
       "      <td>1492.0</td>\n",
       "      <td>1702.0</td>\n",
       "      <td>1468.0</td>\n",
       "      <td>1674.0</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>1647.0</td>\n",
       "      <td>1421.0</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.874254</td>\n",
       "      <td>1.071159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.616982</td>\n",
       "      <td>10.357274</td>\n",
       "      <td>2383.0</td>\n",
       "      <td>3203.2</td>\n",
       "      <td>2344.0</td>\n",
       "      <td>3151.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>3099.8</td>\n",
       "      <td>2269.0</td>\n",
       "      <td>3049.6</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.833725</td>\n",
       "      <td>0.584805</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2.559654</td>\n",
       "      <td>3.410001</td>\n",
       "      <td>868.0</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>854.0</td>\n",
       "      <td>1105.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>826.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.874254</td>\n",
       "      <td>-0.387901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4.354654</td>\n",
       "      <td>4.597610</td>\n",
       "      <td>1406.0</td>\n",
       "      <td>1478.0</td>\n",
       "      <td>1383.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>1338.0</td>\n",
       "      <td>1407.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.687819</td>\n",
       "      <td>0.949570</td>\n",
       "      <td>8.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.772646</td>\n",
       "      <td>1.559058</td>\n",
       "      <td>333.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.833725</td>\n",
       "      <td>0.949570</td>\n",
       "      <td>1.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.218002</td>\n",
       "      <td>0.751867</td>\n",
       "      <td>167.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.833725</td>\n",
       "      <td>0.746923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-0.327051</td>\n",
       "      <td>-0.226352</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.671607</td>\n",
       "      <td>0.746923</td>\n",
       "      <td>9.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         alanine_aminotransferase_10th_percentile  \\\n",
       "cluster                                             \n",
       "0                                       -0.329449   \n",
       "1                                        1.973042   \n",
       "2                                        1.581435   \n",
       "3                                        4.643964   \n",
       "4                                        7.616982   \n",
       "...                                           ...   \n",
       "95                                       2.559654   \n",
       "96                                       4.354654   \n",
       "97                                       0.772646   \n",
       "98                                       0.218002   \n",
       "99                                      -0.327051   \n",
       "\n",
       "         alanine_aminotransferase_90th_percentile  \\\n",
       "cluster                                             \n",
       "0                                       -0.229549   \n",
       "1                                        2.436578   \n",
       "2                                        2.145669   \n",
       "3                                        5.344062   \n",
       "4                                       10.357274   \n",
       "...                                           ...   \n",
       "95                                       3.410001   \n",
       "96                                       4.597610   \n",
       "97                                       1.559058   \n",
       "98                                       0.751867   \n",
       "99                                      -0.226352   \n",
       "\n",
       "         alanine_aminotransferase_binned_10th_percentile  \\\n",
       "cluster                                                    \n",
       "0                                                    2.5   \n",
       "1                                                  692.0   \n",
       "2                                                  575.0   \n",
       "3                                                 1492.0   \n",
       "4                                                 2383.0   \n",
       "...                                                  ...   \n",
       "95                                                 868.0   \n",
       "96                                                1406.0   \n",
       "97                                                 333.0   \n",
       "98                                                 167.0   \n",
       "99                                                   3.0   \n",
       "\n",
       "         alanine_aminotransferase_binned_90th_percentile  \\\n",
       "cluster                                                    \n",
       "0                                                   33.0   \n",
       "1                                                  831.0   \n",
       "2                                                  744.0   \n",
       "3                                                 1702.0   \n",
       "4                                                 3203.2   \n",
       "...                                                  ...   \n",
       "95                                                1123.0   \n",
       "96                                                1478.0   \n",
       "97                                                 568.0   \n",
       "98                                                 326.0   \n",
       "99                                                  33.0   \n",
       "\n",
       "         alanine_aminotransferase_binned_binned_10th_percentile  \\\n",
       "cluster                                                           \n",
       "0                                                      1.5        \n",
       "1                                                    680.0        \n",
       "2                                                    565.0        \n",
       "3                                                   1468.0        \n",
       "4                                                   2344.0        \n",
       "...                                                    ...        \n",
       "95                                                   854.0        \n",
       "96                                                  1383.0        \n",
       "97                                                   327.0        \n",
       "98                                                   164.0        \n",
       "99                                                     2.0        \n",
       "\n",
       "         alanine_aminotransferase_binned_binned_90th_percentile  \\\n",
       "cluster                                                           \n",
       "0                                                     32.0        \n",
       "1                                                    817.0        \n",
       "2                                                    732.0        \n",
       "3                                                   1674.0        \n",
       "4                                                   3151.0        \n",
       "...                                                    ...        \n",
       "95                                                  1105.0        \n",
       "96                                                  1454.0        \n",
       "97                                                   558.0        \n",
       "98                                                   320.0        \n",
       "99                                                    32.0        \n",
       "\n",
       "         alanine_aminotransferase_binned_binned_binned_10th_percentile  \\\n",
       "cluster                                                                  \n",
       "0                                                      0.5               \n",
       "1                                                    669.0               \n",
       "2                                                    555.0               \n",
       "3                                                   1444.0               \n",
       "4                                                   2306.0               \n",
       "...                                                    ...               \n",
       "95                                                   840.0               \n",
       "96                                                  1360.0               \n",
       "97                                                   321.0               \n",
       "98                                                   161.0               \n",
       "99                                                     1.0               \n",
       "\n",
       "         alanine_aminotransferase_binned_binned_binned_90th_percentile  \\\n",
       "cluster                                                                  \n",
       "0                                                     31.0               \n",
       "1                                                    803.0               \n",
       "2                                                    720.0               \n",
       "3                                                   1647.0               \n",
       "4                                                   3099.8               \n",
       "...                                                    ...               \n",
       "95                                                  1087.0               \n",
       "96                                                  1430.0               \n",
       "97                                                   549.0               \n",
       "98                                                   314.0               \n",
       "99                                                    31.0               \n",
       "\n",
       "         alanine_aminotransferase_binned_binned_binned_binned_10th_percentile  \\\n",
       "cluster                                                                         \n",
       "0                                                      0.0                      \n",
       "1                                                    658.0                      \n",
       "2                                                    546.0                      \n",
       "3                                                   1421.0                      \n",
       "4                                                   2269.0                      \n",
       "...                                                    ...                      \n",
       "95                                                   826.0                      \n",
       "96                                                  1338.0                      \n",
       "97                                                   315.0                      \n",
       "98                                                   158.0                      \n",
       "99                                                     0.0                      \n",
       "\n",
       "         alanine_aminotransferase_binned_binned_binned_binned_90th_percentile  \\\n",
       "cluster                                                                         \n",
       "0                                                     30.0                      \n",
       "1                                                    790.0                      \n",
       "2                                                    708.0                      \n",
       "3                                                   1620.0                      \n",
       "4                                                   3049.6                      \n",
       "...                                                    ...                      \n",
       "95                                                  1069.0                      \n",
       "96                                                  1407.0                      \n",
       "97                                                   540.0                      \n",
       "98                                                   309.0                      \n",
       "99                                                    30.0                      \n",
       "\n",
       "         ...  urine_output_10th_percentile  urine_output_90th_percentile  \\\n",
       "cluster  ...                                                               \n",
       "0        ...                     -0.631078                      0.746923   \n",
       "1        ...                     -0.712137                      0.746923   \n",
       "2        ...                     -0.833725                      1.152217   \n",
       "3        ...                     -0.874254                      1.071159   \n",
       "4        ...                     -0.833725                      0.584805   \n",
       "...      ...                           ...                           ...   \n",
       "95       ...                     -0.874254                     -0.387901   \n",
       "96       ...                     -0.687819                      0.949570   \n",
       "97       ...                     -0.833725                      0.949570   \n",
       "98       ...                     -0.833725                      0.746923   \n",
       "99       ...                     -0.671607                      0.746923   \n",
       "\n",
       "         urine_output_binned_10th_percentile  \\\n",
       "cluster                                        \n",
       "0                                       10.0   \n",
       "1                                        7.0   \n",
       "2                                        1.0   \n",
       "3                                        0.0   \n",
       "4                                        1.0   \n",
       "...                                      ...   \n",
       "95                                       0.0   \n",
       "96                                       8.0   \n",
       "97                                       1.0   \n",
       "98                                       1.0   \n",
       "99                                       9.0   \n",
       "\n",
       "         urine_output_binned_90th_percentile  \\\n",
       "cluster                                        \n",
       "0                                       73.0   \n",
       "1                                       73.0   \n",
       "2                                       91.0   \n",
       "3                                       87.4   \n",
       "4                                       65.0   \n",
       "...                                      ...   \n",
       "95                                      21.0   \n",
       "96                                      82.0   \n",
       "97                                      82.0   \n",
       "98                                      73.0   \n",
       "99                                      73.0   \n",
       "\n",
       "         urine_output_binned_binned_10th_percentile  \\\n",
       "cluster                                               \n",
       "0                                              10.0   \n",
       "1                                               7.0   \n",
       "2                                               1.0   \n",
       "3                                               0.0   \n",
       "4                                               1.0   \n",
       "...                                             ...   \n",
       "95                                              0.0   \n",
       "96                                              8.0   \n",
       "97                                              1.0   \n",
       "98                                              1.0   \n",
       "99                                              9.0   \n",
       "\n",
       "         urine_output_binned_binned_90th_percentile  \\\n",
       "cluster                                               \n",
       "0                                              73.0   \n",
       "1                                              73.0   \n",
       "2                                              92.0   \n",
       "3                                              88.4   \n",
       "4                                              65.0   \n",
       "...                                             ...   \n",
       "95                                             21.0   \n",
       "96                                             83.0   \n",
       "97                                             83.0   \n",
       "98                                             73.0   \n",
       "99                                             73.0   \n",
       "\n",
       "         urine_output_binned_binned_binned_10th_percentile  \\\n",
       "cluster                                                      \n",
       "0                                                     10.0   \n",
       "1                                                      7.0   \n",
       "2                                                      1.0   \n",
       "3                                                      0.0   \n",
       "4                                                      1.0   \n",
       "...                                                    ...   \n",
       "95                                                     0.0   \n",
       "96                                                     8.0   \n",
       "97                                                     1.0   \n",
       "98                                                     1.0   \n",
       "99                                                     9.0   \n",
       "\n",
       "         urine_output_binned_binned_binned_90th_percentile  \\\n",
       "cluster                                                      \n",
       "0                                                     73.0   \n",
       "1                                                     73.0   \n",
       "2                                                     93.0   \n",
       "3                                                     89.4   \n",
       "4                                                     65.0   \n",
       "...                                                    ...   \n",
       "95                                                    21.0   \n",
       "96                                                    84.0   \n",
       "97                                                    84.0   \n",
       "98                                                    73.0   \n",
       "99                                                    73.0   \n",
       "\n",
       "         urine_output_binned_binned_binned_binned_10th_percentile  \\\n",
       "cluster                                                             \n",
       "0                                                     10.0          \n",
       "1                                                      7.0          \n",
       "2                                                      1.0          \n",
       "3                                                      0.0          \n",
       "4                                                      1.0          \n",
       "...                                                    ...          \n",
       "95                                                     0.0          \n",
       "96                                                     8.0          \n",
       "97                                                     1.0          \n",
       "98                                                     1.0          \n",
       "99                                                     9.0          \n",
       "\n",
       "         urine_output_binned_binned_binned_binned_90th_percentile  \n",
       "cluster                                                            \n",
       "0                                                     73.0         \n",
       "1                                                     73.0         \n",
       "2                                                     94.0         \n",
       "3                                                     90.4         \n",
       "4                                                     65.0         \n",
       "...                                                    ...         \n",
       "95                                                    21.0         \n",
       "96                                                    85.0         \n",
       "97                                                    85.0         \n",
       "98                                                    73.0         \n",
       "99                                                    73.0         \n",
       "\n",
       "[100 rows x 148 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "52OwxmdZ5Y39",
    "outputId": "45df8c0c-ba7e-4124-b2d9-3c4af46a55ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'creatinine_binned': 701, 'fraction_inspired_oxygen_binned': 279, 'lactate_binned': 844, 'urine_output_binned': 438, 'alanine_aminotransferase_binned': 4617, 'asparate_aminotransferase_binned': 5655, 'mean_blood_pressure_binned': 860, 'diastolic_blood_pressure_binned': 742, 'systolic_blood_pressure_binned': 432, 'gcs_binned': 0, 'partial_pressure_of_oxygen_binned': 409, 'heart_rate_binned': 450, 'temperature_binned': 826, 'respiratory_rate_binned': 1328, 'cluster_binned': 68, 'creatinine_binned_binned': 709, 'fraction_inspired_oxygen_binned_binned': 282, 'lactate_binned_binned': 830, 'urine_output_binned_binned': 443, 'alanine_aminotransferase_binned_binned': 4542, 'asparate_aminotransferase_binned_binned': 5563, 'mean_blood_pressure_binned_binned': 870, 'diastolic_blood_pressure_binned_binned': 730, 'systolic_blood_pressure_binned_binned': 437, 'gcs_binned_binned': 0, 'partial_pressure_of_oxygen_binned_binned': 402, 'heart_rate_binned_binned': 442, 'temperature_binned_binned': 835, 'respiratory_rate_binned_binned': 1343, 'cluster_binned_binned': 68, 'creatinine_binned_binned_binned': 717, 'fraction_inspired_oxygen_binned_binned_binned': 277, 'lactate_binned_binned_binned': 816, 'urine_output_binned_binned_binned': 448, 'alanine_aminotransferase_binned_binned_binned': 4468, 'asparate_aminotransferase_binned_binned_binned': 5473, 'mean_blood_pressure_binned_binned_binned': 855, 'diastolic_blood_pressure_binned_binned_binned': 738, 'systolic_blood_pressure_binned_binned_binned': 442, 'gcs_binned_binned_binned': 0, 'partial_pressure_of_oxygen_binned_binned_binned': 406, 'heart_rate_binned_binned_binned': 447, 'temperature_binned_binned_binned': 845, 'respiratory_rate_binned_binned_binned': 1321, 'cluster_binned_binned_binned': 68, 'creatinine_binned_binned_binned_binned': 725, 'fraction_inspired_oxygen_binned_binned_binned_binned': 280, 'lactate_binned_binned_binned_binned': 802, 'urine_output_binned_binned_binned_binned': 453, 'alanine_aminotransferase_binned_binned_binned_binned': 4396, 'asparate_aminotransferase_binned_binned_binned_binned': 5384, 'mean_blood_pressure_binned_binned_binned_binned': 841, 'diastolic_blood_pressure_binned_binned_binned_binned': 726, 'systolic_blood_pressure_binned_binned_binned_binned': 447, 'gcs_binned_binned_binned_binned': 0, 'partial_pressure_of_oxygen_binned_binned_binned_binned': 410, 'heart_rate_binned_binned_binned_binned': 439, 'temperature_binned_binned_binned_binned': 855, 'respiratory_rate_binned_binned_binned_binned': 1299, 'cluster_binned_binned_binned_binned': 68}\n"
     ]
    }
   ],
   "source": [
    "num_bins_per_column = dict([(column, X_df_binned[column].max()) for column in X_df_binned])\n",
    "print(num_bins_per_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m78IbMJa4P-5"
   },
   "source": [
    "<b> We now create the *splittable* matrix </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "id": "FwFS4VkE6AAJ"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "splittable = []\n",
    "\n",
    "# Iterate over each cluster\n",
    "for index, row in df_clusters.iterrows():\n",
    "    cluster_vector = []\n",
    "\n",
    "    # Iterate over each feature\n",
    "    for feature, bin_edges in bin_edges_dict.items():\n",
    "        # The corresponding binned column in df_clusters\n",
    "        percentile_col_25th = f'{feature}_25th_percentile'\n",
    "        percentile_col_75th = f'{feature}_75th_percentile'\n",
    "\n",
    "        # Check if the percentiles for the feature are in the dataframe\n",
    "        if percentile_col_25th in df_clusters.columns and percentile_col_75th in df_clusters.columns:\n",
    "            # Get the 5th and 95th percentile values for this cluster and feature\n",
    "            percentile_25th_val = row[percentile_col_25th]\n",
    "            percentile_75th_val = row[percentile_col_75th]\n",
    "\n",
    "            # Determine the range of bins that the 5th to 95th percentile values fall into\n",
    "            min_bin_index = np.searchsorted(bin_edges, percentile_25th_val, side='right') - 1\n",
    "            max_bin_index = np.searchsorted(bin_edges, percentile_75th_val, side='left')\n",
    "\n",
    "            # Create a binary vector for this feature in this cluster\n",
    "            feature_vector = np.zeros(len(bin_edges) - 1)\n",
    "            feature_vector[min_bin_index:max_bin_index] = 1\n",
    "            cluster_vector.extend(feature_vector.tolist())\n",
    "\n",
    "    # Add the binary vector for this cluster to the splittable list\n",
    "    splittable.append(cluster_vector)\n",
    "\n",
    "# Convert the splittable list to a DataFrame\n",
    "splittable_df = pd.DataFrame(splittable)\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main input matrix to FIRL\n",
    "splittable = []\n",
    "\n",
    "# Iterate over each cluster\n",
    "for index, row in df_clusters.iterrows():\n",
    "    cluster_vector = []\n",
    "\n",
    "    # Iterate over each feature\n",
    "    for feature, bin_edges in bin_edges_dict.items():\n",
    "        # The corresponding binned column in df_clusters\n",
    "        percentile_col_45th = f'{feature}_{BOTTOM_PERCENTILE}th_percentile'\n",
    "        percentile_col_55th = f'{feature}_{TOP_PERCENTILE}th_percentile'\n",
    "\n",
    "        # Check if the percentiles for the feature are in the dataframe\n",
    "        if percentile_col_45th in df_clusters.columns and percentile_col_55th in df_clusters.columns:\n",
    "            # Get the 5th and 95th percentile values for this cluster and feature\n",
    "            percentile_45th_val = row[percentile_col_45th]\n",
    "            percentile_55th_val = row[percentile_col_55th]\n",
    "\n",
    "            # Determine the range of bins that the 5th to 95th percentile values fall into\n",
    "            min_bin_index = np.searchsorted(bin_edges, percentile_45th_val, side='right') - 1\n",
    "            max_bin_index = np.searchsorted(bin_edges, percentile_55th_val, side='left')\n",
    "\n",
    "            # Create a binary vector for this feature in this cluster\n",
    "            feature_vector = np.zeros(len(bin_edges) - 1)\n",
    "            feature_vector[min_bin_index:max_bin_index] = 1\n",
    "            cluster_vector.extend(feature_vector.tolist())\n",
    "\n",
    "    # Add the binary vector for this cluster to the splittable list\n",
    "    splittable.append(cluster_vector)\n",
    "\n",
    "# Convert the splittable list to a DataFrame\n",
    "splittable_df = pd.DataFrame(splittable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4DMFVA96B-2C",
    "outputId": "996ef65f-4ad2-4613-b595-d14ae4f24e97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splittable_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zPGHo6ym6G-F",
    "outputId": "29954025-bcd6-4e8a-e853-ff29191125fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of binary encoded component features: 69651\n",
      "Cluster 0 and 1 differ by 11284 bits\n",
      "Cluster 0 and 2 differ by 12253 bits\n",
      "Cluster 1 and 2 differ by 3639 bits\n"
     ]
    }
   ],
   "source": [
    "# For testing purposes, we check that the clusters do differ (on a small subset of clusters)\n",
    "print(f\"Total number of binary encoded component features: {len(splittable_df.iloc[0])}\")\n",
    "#n = num_clusters\n",
    "n = 10\n",
    "for i in range(3):\n",
    "  for j in range(i, 3):\n",
    "    # Skip comparing a cluster to itself\n",
    "    if i == j:\n",
    "      continue\n",
    "\n",
    "    contributions = [a==b for a, b in zip(splittable_df.iloc[i], splittable_df.iloc[j])]\n",
    "    print(f\"Cluster {i} and {j} differ by {len([t for t in contributions if not t])} bits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "id": "jikhidCXCWi5"
   },
   "outputs": [],
   "source": [
    "# Now that we have the splittable matrix, we can finally finish creating the\n",
    "# feature_data dict for FIRL\n",
    "\n",
    "# sa_s is a matrix we created previously\n",
    "# that defines whether we *can* transition to state _s from state s by\n",
    "# taking action a. Now, we create the stateadjacency matrix,\n",
    "# which only considers whether two states _s and s are connected by *any*\n",
    "# action, regardless of what that action is\n",
    "\n",
    "# We'll use the csr_matrix from scipy learn\n",
    "# for the sparse matrices we are dealing with here\n",
    "# An alternative would be the lil_matrix class\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "sa_s = mdp_data['sa_s']\n",
    "\n",
    "# Create a 2D matrix for state adjacency\n",
    "stateadjacency_matrix = np.zeros((num_states, num_states), dtype=int)\n",
    "\n",
    "# Fill in the adjacency matrix\n",
    "for s in range(num_states):\n",
    "    for a in range(num_actions):\n",
    "        # Get the possible next states for state 's' when action 'a' is taken\n",
    "        next_states = sa_s[s, a, :]\n",
    "        # Mark the adjacency matrix for each possible next state\n",
    "        for next_state in next_states:\n",
    "            stateadjacency_matrix[s, next_state] = 1\n",
    "\n",
    "# Since stateadjacency_matrix is typically sparse, convert it to a sparse matrix\n",
    "stateadjacency = csr_matrix(stateadjacency_matrix)\n",
    "# ^ The original matlab code does it, but does the same assumption hold for MIMIC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "id": "BI936DvJFKHD"
   },
   "outputs": [],
   "source": [
    "# Finally, the FIRL feature_data:\n",
    "feature_data = {\n",
    "    'stateadjacency': stateadjacency,\n",
    "    'splittable': splittable_df.values\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDZOIbH3FhIz"
   },
   "source": [
    "# FIRL\n",
    "At this point, we are finally ready to run\n",
    "our FIRL algorithm. As described in the midway check-in\n",
    "report the necessary inputs are:\n",
    "\n",
    "- algorithm_params - The parameters of the algorithm. This specifies the hyperparameters for the FIRL algorithm like the number of iterations (of the optimization and fitting steps)\n",
    "\n",
    "- mdp_data - A specification of the example domain. mdp_data includes the number of states, the number of actions, the transition function (specified by sa_s and sa_p). sa_s specifies the what states we can reach from the current state while sa_p specifies the probability of transitioning into every state from the current state. Unlike the simple gridworld case, in the discreticized state spaces we have, the entries of the sa_s matrix are all ones since we assume we can transition from one state to any other state.\n",
    "\n",
    "- feature_data - Information about the features. The FIRL implementation in the gridworld uses this to perform rectangular partitioning of the state space. For example, the state (1, 2) in a gridworld with dimensions 4 X 5, has the component feature [0, 1, 1, 1] and [0, 0, 1, 1, 1]. However, this doesn't immediately apply to our MIMIC states. Hence, after careful thought and considering other options, we reached decidded to split each feature into bins. For example, if blood pressure has values ranging from 0 to 100, we split it into e.g. 5 groups each consisting of 20 values. Then for each for these states, we have the binary encoding. We do these for all the 16 features we have. Thus, each state has 16 * 5 = 80 entries in its component feature.\n",
    "\n",
    "- example_samples - the $\\pi^*$ samples, i.e. trajectories dataset.\n",
    "\n",
    "- true_features - The true features that form a linear basis for the reward. This is the 16 features for each state (if they exist). The feature *extraction* algorithm will ignore these, but these could be useful for e.g. debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def stdvalueiteration(mdp_data, r, vinit=None):\n",
    "    \"\"\"\n",
    "    Run value iteration to solve a standard MDP.\n",
    "\n",
    "    Parameters:\n",
    "        mdp_data (dict): Contains MDP related data.\n",
    "        r (numpy array): Reward function.\n",
    "        vinit (numpy array, optional): Initial value function.\n",
    "\n",
    "    Returns:\n",
    "        numpy array: Computed value function.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Allocate initial value function & variables.\n",
    "    diff = 1.0\n",
    "    if vinit is not None:\n",
    "        vn = vinit\n",
    "    else:\n",
    "        vn = np.zeros(mdp_data['states'])\n",
    "\n",
    "    # Perform value iteration.\n",
    "    while diff >= 1e-8:  # Using 1e-8 as the convergence threshold\n",
    "        vp = vn\n",
    "        vn = np.max(r + np.sum(mdp_data['sa_p'] * vp[mdp_data['sa_s']], axis=2) * mdp_data['discount'], axis=1)\n",
    "        diff = np.max(np.abs(vn - vp))\n",
    "\n",
    "    # Return value function.\n",
    "    return vn\n",
    "\n",
    "\n",
    "def stdpolicy(mdp_data, r, v):\n",
    "    \"\"\"\n",
    "    Given reward and value functions, solve for q function and policy.\n",
    "\n",
    "    Parameters:\n",
    "        mdp_data (dict): Contains MDP related data.\n",
    "        r (numpy array): Reward function.\n",
    "        v (numpy array): Value function.\n",
    "\n",
    "    Returns:\n",
    "        tuple: q function and policy.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute Q function.\n",
    "    q = r + np.sum(mdp_data['sa_p'] * v[mdp_data['sa_s']], axis=2) * mdp_data['discount']\n",
    "\n",
    "    # Compute policy.\n",
    "    p = np.argmax(q, axis=1)\n",
    "\n",
    "    return q, p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "id": "JkYv7X5kFf1_"
   },
   "outputs": [],
   "source": [
    "from time import time as get_time\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from scipy.sparse import csr_matrix\n",
    "# from mdp import stdpolicy, stdvalueiteration\n",
    "\n",
    "class TreeNode:\n",
    "    def __init__(self, type_val, index, test, mean_val, cells=None, ltTree=None, gtTree=None):\n",
    "        self.type = type_val\n",
    "        self.index = index\n",
    "        self.test = test\n",
    "        self.cells = cells\n",
    "        self.mean = mean_val\n",
    "        self.ltTree = ltTree\n",
    "        self.gtTree = gtTree\n",
    "\n",
    "def firlmatchdepth(tree, l1, l2) -> int:\n",
    "    # Check if both leaves match\n",
    "    if tree.type == 0:\n",
    "        if tree.index == l1:\n",
    "            return -1\n",
    "        elif tree.index == l2:\n",
    "            return -2\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        mLeft = firlmatchdepth(tree.ltTree, l1, l2)\n",
    "        mRight = firlmatchdepth(tree.gtTree, l1, l2)\n",
    "        \n",
    "        if (mLeft == -1 or mLeft == -2) and mRight == 0:\n",
    "            return mLeft\n",
    "        elif (mRight == -1 or mRight == -2) and mLeft == 0:\n",
    "            return mRight\n",
    "        elif (mRight == -1 and mLeft == -2) or (mRight == -2 and mLeft == -1):\n",
    "            return 1\n",
    "        else:\n",
    "            matchDepth = max(mLeft, mRight)\n",
    "            if matchDepth > 0:\n",
    "                matchDepth += 1\n",
    "            return matchDepth\n",
    "\n",
    "# Return index of the leaf that contains state s in tree\n",
    "def firlcheckleaf(tree, s, feature_data):\n",
    "\n",
    "    # Check if this is a leaf\n",
    "    if tree.type == 0:\n",
    "        # Return result\n",
    "        return tree.index, tree.mean\n",
    "    else:\n",
    "        # Recurse\n",
    "        if feature_data['splittable'][s, tree.test] == 0:\n",
    "            branch = tree.ltTree\n",
    "        else:\n",
    "            branch = tree.gtTree\n",
    "        \n",
    "        return firlcheckleaf(branch, s, feature_data)\n",
    "\n",
    "\n",
    "def firlaveragereward(tree, R, actions):\n",
    "    \"\"\"\n",
    "    Compute the closest reward function that can be represented by the given tree.\n",
    "\n",
    "    Args:\n",
    "    - tree: the tree structure with attributes `type`, `cells`, and `mean`.\n",
    "    - R: the reward function matrix.\n",
    "    - actions: the number of actions.\n",
    "\n",
    "    Returns:\n",
    "    - Rout: the updated reward function.\n",
    "    \"\"\"\n",
    "    if tree.type == 0:\n",
    "        count = len(tree.cells)\n",
    "\n",
    "        # Replace the relevant section of the reward function.\n",
    "        for i in range(count):\n",
    "            s = tree.cells[i]\n",
    "            for a in range(actions):\n",
    "                R[s][a] = tree.mean[a]\n",
    "        Rout = R\n",
    "    else:\n",
    "        R = firlaveragereward(tree.ltTree, R, actions)\n",
    "        R = firlaveragereward(tree.gtTree, R, actions)\n",
    "        Rout = R\n",
    "    return Rout\n",
    "\n",
    "def firldefaultparams(algorithm_params={}):\n",
    "    \"\"\"\n",
    "    Fill in default parameters for the FIRL algorithm.\n",
    "\n",
    "    Args:\n",
    "    - algorithm_params: dictionary containing provided parameters.\n",
    "\n",
    "    Returns:\n",
    "    - algorithm_params: dictionary containing all parameters with defaults filled in.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create default parameters\n",
    "    default_params = {\n",
    "        'seed': 0,\n",
    "        'iterations': 10,\n",
    "        'depth_step': 1,\n",
    "        'init_depth': 0\n",
    "    }\n",
    "    \n",
    "    # Set parameters with defaults if not provided\n",
    "    for key, value in default_params.items():\n",
    "        algorithm_params.setdefault(key, value)\n",
    "    \n",
    "    return algorithm_params\n",
    "\n",
    "def firlregressiontree(st_states, depth, leavesIn, Eo, R, V, split_thresh, max_depth, mdp_data, feature_data):\n",
    "    \"\"\"\n",
    "    Construct decision subtree.\n",
    "    \"\"\"\n",
    "    leaves = leavesIn\n",
    "    test = 1\n",
    "    G = float('inf')\n",
    "\n",
    "    if depth > max_depth:\n",
    "        makeLeaf = False\n",
    "        fMean = R[st_states, :].mean(axis=0)\n",
    "    else:\n",
    "        # Step over all possible splitting moves\n",
    "        for tTest in range(feature_data['splittable'].shape[1]):\n",
    "            # Split the examples\n",
    "            st_splits = feature_data['splittable'][st_states, tTest]\n",
    "            lt_states = st_states[st_splits == 0]\n",
    "            gt_states = st_states[st_splits == 1]\n",
    "\n",
    "            # Compute mean\n",
    "            ltMean = R[lt_states, :].mean()\n",
    "            gtMean = R[gt_states, :].mean()\n",
    "            ltVar = ((R[lt_states, :] - ltMean) ** 2).sum()\n",
    "            gtVar = ((R[gt_states, :] - gtMean) ** 2).sum()\n",
    "            value = ltVar + gtVar\n",
    "\n",
    "            if len(lt_states) > 0 and len(gt_states) > 0 and value < G:\n",
    "                G = value\n",
    "                test = tTest\n",
    "\n",
    "        # Construct the partitions\n",
    "        st_splits = feature_data['splittable'][st_states, test]\n",
    "        lt_states = st_states[st_splits == 0]\n",
    "        gt_states = st_states[st_splits == 1]\n",
    "        fMean = R[st_states, :].mean(axis=0)\n",
    "        fullMean = fMean.mean()\n",
    "        maxDeviation = ((R[st_states, :] - fullMean) ** 2).max(axis=0).max()\n",
    "\n",
    "\n",
    "        if maxDeviation > (split_thresh ** 2) and len(st_states) > 1:\n",
    "            # Test if this node should be prunable\n",
    "            Rnew = R.copy()\n",
    "            Rnew[st_states, :] = fMean\n",
    "            Vnew = stdvalueiteration(mdp_data, Rnew, V)\n",
    "            _, P = stdpolicy(mdp_data, Rnew, Vnew)\n",
    "\n",
    "            # Test if P matches all non-zero values of Eo\n",
    "            mismatches = Eo * (P != Eo)\n",
    "            makeLeaf = len(np.nonzero(mismatches)[0]) != 0\n",
    "        else:\n",
    "            makeLeaf = False\n",
    "\n",
    "    if makeLeaf and len(st_states) > 1 and G != float('inf'):\n",
    "        # Create node with the best split\n",
    "        rightTree, leaves, R, V = firlregressiontree(gt_states, depth+1, leaves, Eo, R, V, split_thresh, max_depth, mdp_data, feature_data)\n",
    "        leftTree, leaves, R, V = firlregressiontree(lt_states, depth+1, leaves, Eo, R, V, split_thresh, max_depth, mdp_data, feature_data)\n",
    "        \n",
    "        # Create node. TreeNode constructor parameters:\n",
    "        # type_val, index, test, mean_val, cells=None, ltTree=None, gtTree=None\n",
    "        tree = TreeNode(1, None, test, fMean, st_states.tolist(), leftTree, rightTree)\n",
    "        Rout = R\n",
    "        Vout = V\n",
    "    else:\n",
    "        # Create leaf node\n",
    "        # tree = {'type': 0, 'index': leaves + 1, 'mean': fMean, 'cells': st_states.tolist()}\n",
    "        tree = TreeNode(0, leaves, None, fMean, st_states.tolist())\n",
    "        leaves += 1\n",
    "        Rout = R\n",
    "        Vout = V\n",
    "\n",
    "    return tree, leaves, Rout, Vout\n",
    "\n",
    "\n",
    "def firloptimization(Eo, Rold, ProjToLeaf, LeafToProj, FeatureMatch, mdp_data, verbosity):\n",
    "    \"\"\"\n",
    "    Runs the optimization phase to compute a reward function that is close to \n",
    "    the current feature hypothesis \n",
    "    \"\"\"\n",
    "\n",
    "    # Smoothing term (relative to reward objective)\n",
    "    # SMOOTH_WEIGHT = 0.02\n",
    "    SMOOTH_WEIGHT = 0.001\n",
    "\n",
    "    # Total size\n",
    "    states = mdp_data['states']\n",
    "    actions = mdp_data['actions']\n",
    "    msize = states * actions\n",
    "    results = mdp_data['sa_s'].shape[2]\n",
    "\n",
    "    ### Constraint construction ###\n",
    "    cols = np.nonzero(Eo)[0]\n",
    "    examples = len(cols)\n",
    "\n",
    "    sN = np.zeros(msize - examples * actions, dtype=int)            # start state idxs\n",
    "    rN = np.zeros(msize - examples * actions, dtype=int)            # state-action idxs\n",
    "    eN = np.zeros((msize - examples * actions, results), dtype=int) # resultant state idxs\n",
    "    pN = np.zeros((msize - examples * actions, results))            # resultant state coeffs\n",
    "\n",
    "    sM = np.zeros(examples * (actions - 1), dtype=int)\n",
    "    rM = np.zeros(examples * (actions - 1), dtype=int)\n",
    "    eM = np.zeros((examples * (actions - 1), results), dtype=int)\n",
    "    pM = np.zeros((examples * (actions - 1), results))\n",
    "\n",
    "    sE = np.zeros(examples, dtype=int)\n",
    "    rE = np.zeros(examples, dtype=int)\n",
    "    eE = np.zeros((examples, results), dtype=int)\n",
    "    pE = np.zeros((examples, results))\n",
    "\n",
    "    Nrow = 0\n",
    "    Mrow = 0\n",
    "    Erow = 0\n",
    "    for startstate in range(states):\n",
    "        if Eo[startstate] != 0:\n",
    "            # We generate destination state and reward under the optimal action\n",
    "            optaction = Eo[startstate]\n",
    "            reward = actions * startstate + optaction\n",
    "\n",
    "            sE[Erow] = startstate\n",
    "            rE[Erow] = reward\n",
    "            eE[Erow, :] = mdp_data['sa_s'][startstate, optaction, :]\n",
    "            pE[Erow, :] = mdp_data['sa_p'][startstate, optaction, :] * mdp_data['discount']\n",
    "            Erow += 1\n",
    "\n",
    "            for action in range(actions):\n",
    "                if action != optaction:\n",
    "                    reward = actions * startstate + action\n",
    "\n",
    "                    sM[Mrow] = startstate\n",
    "                    rM[Mrow] = reward\n",
    "                    eM[Mrow, :] = mdp_data['sa_s'][startstate, action, :]\n",
    "                    pM[Mrow, :] = mdp_data['sa_p'][startstate, action, :] * mdp_data['discount']\n",
    "                    Mrow += 1\n",
    "        else:\n",
    "            for action in range(actions):\n",
    "                # Generate destination state and reward indices\n",
    "                reward = actions * startstate + action\n",
    "\n",
    "                sN[Nrow] = startstate\n",
    "                rN[Nrow] = reward\n",
    "                eN[Nrow, :] = mdp_data['sa_s'][startstate, action, :]\n",
    "                pN[Nrow, :] = mdp_data['sa_p'][startstate, action, :] * mdp_data['discount']\n",
    "                Nrow += 1\n",
    "\n",
    "    # Determine number of leaves\n",
    "    _, msize = ProjToLeaf.shape\n",
    "    leafEntries, leaves = FeatureMatch.shape\n",
    "\n",
    "    # Margin by which examples should be optimal\n",
    "    MARGIN = 0.01\n",
    "    margins = np.ones(examples * (actions - 1)) * MARGIN\n",
    "\n",
    "    EPSILON = 2.22e-16\n",
    "    r = cp.Variable(msize)\n",
    "    v = cp.Variable(states)\n",
    "    f = cp.Variable(leaves)\n",
    "\n",
    "    objective = cp.Minimize(cp.norm(LeafToProj @ f - r) ** 2 / msize +\n",
    "        cp.norm(FeatureMatch @ f, 1) * (SMOOTH_WEIGHT / (leafEntries * 500)))\n",
    "\n",
    "    constraints = [\n",
    "        f == ProjToLeaf @ r,\n",
    "        #v[sN] >= r[rN] + cp.sum(cp.multiply(v[eN], pN), axis=1),\n",
    "        #v[sM] >= r[rM] + cp.sum(cp.multiply(v[eM],pM), axis=1) + margins,\n",
    "        #v[sE] == r[rE] + cp.sum(cp.multiply(v[eE], pE), axis=1)\n",
    "    ]\n",
    "\n",
    "    # NOTE: In CVXPY, we can't index a variable directly with a list or array\n",
    "    # of indices like we can in MATLAB. Hence:\n",
    "\n",
    "    # Add constraints for sN, rN, eN, and pN\n",
    "    for idx in range(len(sN)):\n",
    "        constraints.append(v[sN[idx]] >= r[rN[idx]] +\n",
    "                           cp.sum(cp.multiply(v[eN[idx, :]], pN[idx, :])))\n",
    "\n",
    "    # Add constraints for sM, rM, eM, and pM with margins\n",
    "    for idx in range(len(sM)):\n",
    "        constraints.append(v[sM[idx]] >= r[rM[idx]] +\n",
    "                           cp.sum(cp.multiply(v[eM[idx, :]], pM[idx, :])) + margins[idx])\n",
    "\n",
    "    # Add constraints for sE, rE, eE, and pE\n",
    "    for idx in range(len(sE)):\n",
    "        constraints.append(v[sE[idx]] == r[rE[idx]] +\n",
    "                           cp.sum(cp.multiply(v[eE[idx, :]], pE[idx, :])))\n",
    "\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve(verbose=verbosity == 2)\n",
    "\n",
    "    if Rold.shape[0] > 1 and np.isnan(prob.value):\n",
    "        if verbosity != 0:\n",
    "            print('WARNING: Failed to obtain solution, reverting to old reward!')\n",
    "        R = Rold\n",
    "    else:\n",
    "        # Recover the reward function\n",
    "        R = r.value.reshape(actions, states).T\n",
    "\n",
    "    return R, MARGIN\n",
    "\n",
    "\n",
    "\n",
    "def firlprojectionfromtree(tree, leaves, states, actions, feature_data):\n",
    "    \n",
    "    DEPTH_WEIGHT = 1\n",
    "    \n",
    "    # Matrix of adjacencies.\n",
    "    adjleaves = csr_matrix((leaves, leaves), dtype=np.int32)\n",
    "    stateleaves = np.zeros(states, dtype=np.int32)\n",
    "    \n",
    "    # Count number of elements in each leaf and assign leaf to each state.\n",
    "    elements = np.zeros(leaves, dtype=np.int32)\n",
    "    for s in range(states):\n",
    "        leaf, _mean = firlcheckleaf(tree, s, feature_data)\n",
    "        elements[leaf] += 1\n",
    "        stateleaves[s] = leaf\n",
    "        \n",
    "    # Count pairs and build adjacency matrix.\n",
    "    pairs = 0\n",
    "    for s in range(states):\n",
    "        leaf = stateleaves[s]\n",
    "        adj = np.nonzero(feature_data['stateadjacency'][s, :])[0]\n",
    "        numadj = len(adj)\n",
    "        \n",
    "        # Write out adjacencies\n",
    "        for i in adj:\n",
    "            lother = stateleaves[i]\n",
    "            if lother != leaf:\n",
    "                # Found adjacency\n",
    "                if adjleaves[lother, leaf] == 0 and adjleaves[leaf, lother] == 0:\n",
    "                    pairs += 1\n",
    "                adjleaves[lother, leaf] = 1\n",
    "                adjleaves[leaf, lother] = 1\n",
    "                \n",
    "    # Construct feature match matrix\n",
    "    FeatureMatch = csr_matrix((pairs, leaves), dtype=np.float64)\n",
    "    idx = 0\n",
    "    maxPair = 0\n",
    "    for l1 in range(leaves):\n",
    "        for l2 in range(l1 + 1, leaves):\n",
    "            adjacent = adjleaves[l1, l2]\n",
    "            if adjacent > 0:\n",
    "                matchDepth = (firlmatchdepth(tree, l1, l2) - 1)\n",
    "                FeatureMatch[idx, l1] = adjacent + matchDepth * DEPTH_WEIGHT\n",
    "                FeatureMatch[idx, l2] = -adjacent - matchDepth * DEPTH_WEIGHT\n",
    "                if FeatureMatch[idx, l1] > maxPair:\n",
    "                    maxPair = FeatureMatch[idx, l1]\n",
    "                idx += 1\n",
    "    \n",
    "    if pairs <= 0:\n",
    "        # Handle degeneracy\n",
    "        FeatureMatch = csr_matrix((1, leaves), dtype=np.float64)\n",
    "    else:\n",
    "        FeatureMatch = FeatureMatch / maxPair\n",
    "    \n",
    "    # Construct projection matrix\n",
    "    ProjToLeaf = csr_matrix((leaves, states * actions), dtype=np.float64)\n",
    "    LeafToProj = csr_matrix((states * actions, leaves), dtype=np.float64)\n",
    "    \n",
    "    for s in range(states):\n",
    "        leaf = stateleaves[s]\n",
    "        for a in range(actions):\n",
    "            pos = s * actions + a\n",
    "            ProjToLeaf[leaf, pos] = 1.0 / (elements[leaf] * actions)\n",
    "            LeafToProj[pos, leaf] = 1.0\n",
    "\n",
    "    # Convert to CSR for efficient operations in future usage\n",
    "    return ProjToLeaf.tocsr(), LeafToProj.tocsr(), FeatureMatch.tocsr()\n",
    "\n",
    "\n",
    "def firlrun(algorithm_params, mdp_data, mdp_model, feature_data, example_samples, _, verbosity):\n",
    "\n",
    "    # Fill in default parameters\n",
    "    algorithm_params = firldefaultparams(algorithm_params)\n",
    "\n",
    "    np.random.seed(algorithm_params['seed'])\n",
    "\n",
    "    # Initialize variables\n",
    "    states = mdp_data['states']\n",
    "    actions = mdp_data['actions']\n",
    "    iterations = algorithm_params['iterations']\n",
    "    depth_step = algorithm_params['depth_step']\n",
    "    init_depth = algorithm_params['init_depth']\n",
    "\n",
    "    # Construct mapping from states to example actions\n",
    "    Eo = np.zeros(states, dtype=int)\n",
    "    for i in range(len(example_samples)):\n",
    "        for t in range(len(example_samples[i])):\n",
    "            Eo[example_samples[i][t][0]] = example_samples[i][t][1]\n",
    "\n",
    "    # Construct initial tree\n",
    "    leaves = 1\n",
    "    # Note: In python should be zero indexed\n",
    "    # tree = {'type': 0, 'index': 0, 'mean': np.zeros(actions)}\n",
    "    tree = TreeNode(0, 0, None, np.zeros(actions))\n",
    "    ProjToLeaf, LeafToProj, FeatureMatch = firlprojectionfromtree(tree, leaves, states, actions, feature_data)\n",
    "\n",
    "    # Prepare timing variables.\n",
    "    optTime, fitTime, vitTime, matTime = [np.zeros(iterations) for _ in range(4)]\n",
    "    \n",
    "    # Prepare intermediate output variables\n",
    "    opt_acc_itr = [None] * (iterations)\n",
    "    r_itr = [None] * (iterations)\n",
    "    p_itr = [None] * (iterations)\n",
    "    model_itr = [None] * (iterations)\n",
    "    model_r_itr = [None] * (iterations)\n",
    "    model_p_itr = [None] * (iterations)\n",
    "    \n",
    "    # Run firl.\n",
    "    Rold = np.random.normal(size=(states, actions))\n",
    "    itr = 0\n",
    "    while True:\n",
    "        if verbosity != 0:\n",
    "            print(f'Beginning FIRL iteration {itr+1}')\n",
    "\n",
    "        # Run optimization phase\n",
    "        start_time = get_time()\n",
    "        R, margin = firloptimization(Eo, Rold, ProjToLeaf, LeafToProj, FeatureMatch, mdp_data, verbosity)\n",
    "        Rold = R\n",
    "        threshold = margin * 0.2 * mdp_data['discount']\n",
    "        optTime[itr] = get_time() - start_time\n",
    "\n",
    "        # Generate policy\n",
    "        start_time = get_time()\n",
    "        V = stdvalueiteration(mdp_data, R)\n",
    "        _, P = stdpolicy(mdp_data, R, V)\n",
    "        vitTime[itr] = get_time() - start_time\n",
    "\n",
    "        # Construct tree\n",
    "        start_time = get_time()\n",
    "        # Adjust Eo to exclude violated examples\n",
    "        # In an exact optimization, there should be no violated examples\n",
    "        # However, an approximation might violate some examples\n",
    "        Eadjusted = Eo * (P == Eo)\n",
    "        totalExamples = np.sum(Eadjusted > 0)\n",
    "        #opt_acc_itr.append(totalExamples / np.sum(Eo > 0))\n",
    "        opt_acc_itr[itr] = totalExamples / np.sum(Eo > 0)\n",
    "        max_depth = init_depth + itr * depth_step\n",
    "        tree, leaves, _, _ = firlregressiontree(\n",
    "            np.arange(states),      # Start with all states\n",
    "            0,                      # Current depth\n",
    "            0,                      # First leaf index\n",
    "            Eadjusted,              # Pass in part of policy we want to match\n",
    "            R,                      # Pass in reward function\n",
    "            V,                      # Pass in value function\n",
    "            threshold,              # Pass in termination threshold\n",
    "            max_depth,              # Pass in maximum depth\n",
    "            mdp_data,               # Pass in MDP data\n",
    "            feature_data            # Pass in feature data\n",
    "        )\n",
    "        fitTime[itr] = get_time() - start_time\n",
    "\n",
    "        # Construct projection matrices\n",
    "        start_time = get_time()\n",
    "        ProjToLeaf, LeafToProj, FeatureMatch = firlprojectionfromtree(tree, leaves, states, actions, feature_data)\n",
    "        matTime[itr] = get_time() - start_time\n",
    "\n",
    "        # Record policy at this iteration\n",
    "        #r_itr.append(R)\n",
    "        #p_itr.append(P)\n",
    "        #model_itr.append(tree)\n",
    "        r_itr[itr] = R\n",
    "        p_itr[itr] = P\n",
    "        model_itr[itr] = tree\n",
    "\n",
    "        # Increment iteration\n",
    "        itr += 1\n",
    "        if itr >= iterations:\n",
    "            break\n",
    "\n",
    "    # Compute final policy\n",
    "    Rout = firlaveragereward(tree, R, actions)\n",
    "    Vout = stdvalueiteration(mdp_data, Rout)\n",
    "    Qout, Pout = stdpolicy(mdp_data, Rout, Vout)\n",
    "\n",
    "    # Compute all intermediate policies\n",
    "    for i in range(iterations):\n",
    "        model_r_itr[i] = firlaveragereward(model_itr[i], r_itr[i], actions)\n",
    "        v = stdvalueiteration(mdp_data, model_r_itr[i])\n",
    "        _, model_p_itr[i] = stdpolicy(mdp_data, model_r_itr[i], v)\n",
    "\n",
    "    if verbosity != 0:\n",
    "        # Report timing\n",
    "        for itr in range(iterations):\n",
    "            print(f'Iteration {itr + 1} optimization: {optTime[itr]:.6f}s')\n",
    "            print(f'Iteration {itr + 1} value iteration: {vitTime[itr]:.6f}s')\n",
    "            print(f'Iteration {itr + 1} fitting: {fitTime[itr]:.6f}s')\n",
    "            print(f'Iteration {itr + 1} objective construction: {matTime[itr]:.6f}s')\n",
    "\n",
    "    total = sum(optTime) + sum(vitTime) + sum(fitTime) + sum(matTime)\n",
    "    if verbosity != 0:\n",
    "        print(f'Total time: {total:.6f}s\\n')\n",
    "\n",
    "    time = total\n",
    "    mean_opt_time = np.mean(optTime)\n",
    "    mean_fit_time = np.mean(fitTime)\n",
    "\n",
    "    # Build output structure\n",
    "    irl_result = {\n",
    "        'r': Rout,\n",
    "        'v': Vout,\n",
    "        'q': Qout,\n",
    "        'p': Pout,\n",
    "        'opt_acc_itr': opt_acc_itr,\n",
    "        'r_itr': r_itr,\n",
    "        'model_itr': model_itr,\n",
    "        'model_r_itr': model_r_itr,\n",
    "        'p_itr': p_itr,\n",
    "        'model_p_itr': model_p_itr,\n",
    "        'time': time,\n",
    "        'mean_opt_time': mean_opt_time,\n",
    "        'mean_fit_time': mean_fit_time\n",
    "    }\n",
    "\n",
    "    return irl_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VLbLdDg2Lyf7",
    "outputId": "b89e8944-7cc2-42a7-893c-eb2ccafaf989"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories_tmp = [t.transitions() for t in trajectories]\n",
    "type(trajectories_tmp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "HJIZS7UIG1G5",
    "outputId": "d38f12c6-914e-47d4-8875-9106237569f9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkjm/.local/lib/python3.10/site-packages/scipy/sparse/_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning FIRL iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21574/1855083379.py:132: RuntimeWarning: Mean of empty slice.\n",
      "  gtMean = R[gt_states, :].mean()\n",
      "/home/mkjm/.local/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_21574/1855083379.py:131: RuntimeWarning: Mean of empty slice.\n",
      "  ltMean = R[lt_states, :].mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning FIRL iteration 2\n",
      "Beginning FIRL iteration 3\n"
     ]
    }
   ],
   "source": [
    "# firlrun() takes in the arguments as specified previously\n",
    "\n",
    "# For the unused arguments, we use the defaults\n",
    "algorithm_params = {'iterations': 25}\n",
    "mdp_model = None\n",
    "example_samples = trajectories_tmp\n",
    "verbosity = 1\n",
    "\n",
    "# Run FIRL\n",
    "res = firlrun(algorithm_params, mdp_data, mdp_model, feature_data, example_samples, None, verbosity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(res['r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(res['model_r_itr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing best and worst clusters\n",
    "We sort based on the value function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['model_itr'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res['v'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_clusters = np.argsort(res['v'])\n",
    "sorted_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5 = sorted_clusters[-5::][::-1]\n",
    "bottom_5 = sorted_clusters[:5][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_clusters = list(top_5) + list(bottom_5)\n",
    "selected_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res['v'][selected_clusters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = data_non_normalized_df.columns[:-2] # no cluster / action cols\n",
    "means = pd.DataFrame(columns=features, index=selected_clusters)\n",
    "\n",
    "for cluster in selected_clusters:\n",
    "    subset = data_non_normalized_df[data_non_normalized_df['cluster'] == cluster]\n",
    "    means.loc[cluster, features] = subset[features].mean()\n",
    "    \n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "normalized_means = (means - means.min()) / (means.max() - means.min())\n",
    "normalized_means = normalized_means.astype(float)\n",
    "normalized_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "custom_labels = ['Best Cluster', 'Second Best Cluster', 'Third Best Cluster', 'Fourth Best Cluster', 'Fifth Best Cluster', \n",
    "                 'Fifth Worst Cluster', 'Fourth Worst Cluster', 'Third Worst Cluster', 'Second Worst Cluster', 'Worst Cluster']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(normalized_means.T, cmap=\"YlGnBu\", annot=means.T, fmt=\".2f\")\n",
    "plt.xticks(ticks=np.arange(len(custom_labels)), labels=custom_labels, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy: \n",
    "Compare accuracy to the training set actions (y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "firl_policy = res['p']\n",
    "accuracy = sum((firl_policy[data_df['cluster']]) == y_df) / len(y_df)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(firl_policy)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
